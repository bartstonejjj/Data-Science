{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Adjust display settings\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_colwidth', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging the datasets and cleaning the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data: MovieLens _ml\n",
    "# Read in Movies and Ratings from MovieLens Data\n",
    "data_dir = '/home/justin/Documents/Data Science/Data'\n",
    "mov_ml = pd.read_csv(data_dir + '/MovieLens/ml-latest/movies.csv')\n",
    "rat_ml = pd.read_csv(data_dir + '/MovieLens/ml-latest/ratings.csv')\n",
    "\n",
    "# Convert out of 5 ratings, to out of 10 ratings\n",
    "rat_ml['rating'] = rat_ml['rating'] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.789603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.442171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.360189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.759455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.161622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rating\n",
       "movieId          \n",
       "1        7.789603\n",
       "2        6.442171\n",
       "3        6.360189\n",
       "4        5.759455\n",
       "5        6.161622"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data: MovieLens _ml\n",
    "# Find the average movie rating and store in 'mr', remove those without a rating\n",
    "mov_rat_ml = pd.DataFrame(rat_ml[['movieId','rating']].groupby('movieId').mean())\n",
    "mov_rat_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>81296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>79091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>77887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>76271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>69545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_ratings\n",
       "movieId             \n",
       "356            81296\n",
       "296            79091\n",
       "318            77887\n",
       "593            76271\n",
       "480            69545"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data: MovieLens _ml\n",
    "# Count the number of ratings and store in 'mc'. Sort by highest number of ratings first\n",
    "mov_num_rat_ml = pd.DataFrame(rat_ml[['movieId','rating']].groupby('movieId').size(), columns=['num_ratings']).sort_values(by='num_ratings', ascending=0)\n",
    "mov_num_rat_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60424</td>\n",
       "      <td>7.789603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23950</td>\n",
       "      <td>6.442171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15267</td>\n",
       "      <td>6.360189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2935</td>\n",
       "      <td>5.759455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14769</td>\n",
       "      <td>6.161622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_ratings    rating\n",
       "movieId                       \n",
       "1              60424  7.789603\n",
       "2              23950  6.442171\n",
       "3              15267  6.360189\n",
       "4               2935  5.759455\n",
       "5              14769  6.161622"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data: MovieLens\n",
    "# Show all movies, number of ratings 'num_ratings' and average rating 'rating'\n",
    "mov_rat_agg_ml = mov_num_rat_ml.merge(mov_rat_ml, right_index=1, left_index=1)\n",
    "mov_rat_agg_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33664 entries, 0 to 33663\n",
      "Data columns (total 5 columns):\n",
      "title          33664 non-null object\n",
      "genres         33664 non-null object\n",
      "movieId        33664 non-null float64\n",
      "num_ratings    33664 non-null float64\n",
      "rating         33664 non-null float64\n",
      "dtypes: float64(3), object(2)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Data: MovieLens _ml\n",
    "# Aggregate all movies, and ratings stats into one Dataframe (Note: this removes unrated films)\n",
    "# Sort by top movies if sorted by average rating, then number of ratings\n",
    "agg_ml = (mov_ml.merge(mov_rat_agg_ml,how='inner', left_on='movieId',right_index=1).groupby(['title','genres']).mean().\n",
    "    sort_values(['rating','num_ratings'], ascending=[0,0]))\n",
    "agg_ml.reset_index(inplace=True)\n",
    "agg_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>movieId</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De la servitude moderne</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>106517.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dilwale</td>\n",
       "      <td>Action|Children|Comedy|Crime|Drama|Romance</td>\n",
       "      <td>150268.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naked Among Wolves</td>\n",
       "      <td>Drama|War</td>\n",
       "      <td>148030.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Fruit Hunters</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>133323.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Girl in the Book</td>\n",
       "      <td>Drama</td>\n",
       "      <td>148701.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                      genres  \\\n",
       "0  De la servitude moderne                                 Documentary   \n",
       "1                  Dilwale  Action|Children|Comedy|Crime|Drama|Romance   \n",
       "2       Naked Among Wolves                                   Drama|War   \n",
       "3        The Fruit Hunters                                 Documentary   \n",
       "4     The Girl in the Book                                       Drama   \n",
       "\n",
       "    movieId  num_ratings  rating  year  \n",
       "0  106517.0          2.0    10.0  2009  \n",
       "1  150268.0          2.0    10.0  2015  \n",
       "2  148030.0          2.0    10.0  2015  \n",
       "3  133323.0          2.0    10.0  2012  \n",
       "4  148701.0          2.0    10.0  2015  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data: MovieLens\n",
    "# Separate the year from the title into separate columns for MovieLens titles\n",
    "df = agg_ml.copy()\n",
    "df['year'] = df.title.str.extract('[(](\\d{4})[)]') \n",
    "df['title'] = df.title.str.replace(r' [(]\\d{4}[)]', '')\n",
    "df['year'].fillna('0', inplace=True)\n",
    "df['year'] = df['year'].astype(int)\n",
    "agg_sepYr_ml = df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>movieId</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>has_the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>The Barchester Chronicles</td>\n",
       "      <td>Drama</td>\n",
       "      <td>95517.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1982</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>The Best of Ernie and Bert</td>\n",
       "      <td>Children</td>\n",
       "      <td>94972.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1988</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>The Keeping the Promise (Sign of the Beaver)</td>\n",
       "      <td>Children|Drama</td>\n",
       "      <td>93967.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1997</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>The New Rulers of the World</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>114011.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>The On Any Sunday Next Chapter</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>133964.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title          genres   movieId  \\\n",
       "42                      The Barchester Chronicles           Drama   95517.0   \n",
       "43                     The Best of Ernie and Bert        Children   94972.0   \n",
       "115  The Keeping the Promise (Sign of the Beaver)  Children|Drama   93967.0   \n",
       "142                   The New Rulers of the World     Documentary  114011.0   \n",
       "143                The On Any Sunday Next Chapter     Documentary  133964.0   \n",
       "\n",
       "     num_ratings  rating  year has_the  \n",
       "42           1.0    10.0  1982    True  \n",
       "43           1.0    10.0  1988    True  \n",
       "115          1.0    10.0  1997    True  \n",
       "142          1.0    10.0  2001    True  \n",
       "143          1.0    10.0  2014    True  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data: MovieLens\n",
    "# Move the 'The' to the start for MovieLens titles to help with matching\n",
    "# (e.g. \"Usual Suspects, The\" in MovieLens is \"The Usual Suspects\" in IMDB & OMDB)\n",
    "df = agg_sepYr_ml.copy()\n",
    "df['has_the'] = df.title.str.contains(', The')\n",
    "df.title = df.title.str.replace(r', The', '')\n",
    "df.ix[df.has_the, 'title'] = 'The ' + df.ix[df.has_the, 'title']\n",
    "agg_sepYr_moveThe_ml = df\n",
    "df[df.has_the].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33664 entries, 0 to 33663\n",
      "Data columns (total 7 columns):\n",
      "title          33664 non-null object\n",
      "genres         33664 non-null object\n",
      "movieId        33664 non-null float64\n",
      "num_ratings    33664 non-null float64\n",
      "rating         33664 non-null float64\n",
      "year           33664 non-null int64\n",
      "has_the        33664 non-null bool\n",
      "dtypes: bool(1), float64(3), int64(1), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "agg_sepYr_moveThe_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>movieId</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>has_the</th>\n",
       "      <th>has_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>A Christmasgain</td>\n",
       "      <td>(no genres listed)</td>\n",
       "      <td>148857.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>A Child's Christmas in Wales</td>\n",
       "      <td>Children|Drama</td>\n",
       "      <td>95837.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.25</td>\n",
       "      <td>1987</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>A Season for Miracles</td>\n",
       "      <td>Children|Romance</td>\n",
       "      <td>98699.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1999</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>A Fine Madness</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>31638.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1966</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>A Englishugust</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>139895.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1994</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title                genres   movieId  \\\n",
       "57                A Christmasgain    (no genres listed)  148857.0   \n",
       "305  A Child's Christmas in Wales        Children|Drama   95837.0   \n",
       "323         A Season for Miracles      Children|Romance   98699.0   \n",
       "343                A Fine Madness  Comedy|Drama|Romance   31638.0   \n",
       "454                A Englishugust          Comedy|Drama  139895.0   \n",
       "\n",
       "     num_ratings  rating  year has_the has_a  \n",
       "57           1.0   10.00  2015   False  True  \n",
       "305          4.0    9.25  1987   False  True  \n",
       "323          3.0    9.00  1999   False  True  \n",
       "343          2.0    9.00  1966   False  True  \n",
       "454          1.0    9.00  1994   False  True  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data: MovieLens\n",
    "# Move the 'A' to the start for MovieLens titles to help with matching\n",
    "# (e.g. )\n",
    "df = agg_sepYr_moveThe_ml.copy()\n",
    "df['has_a'] = df.title.str.contains(', A')\n",
    "df.title = df.title.str.replace(r', A', '')\n",
    "df.ix[df.has_a, 'title'] = 'A ' + df.ix[df.has_a, 'title']\n",
    "agg_sepYr_moveThe_moveA_ml = df\n",
    "df[df.has_a].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to normalise title names, by removing : and - and making titles in \"Title Case Which Is Like This\"\n",
    "# Will replace 'title' with normalised title\n",
    "def normlise_title(df):\n",
    "    df.title = df.title.str.replace(r'&', 'and')\n",
    "    df.title = df.title.str.replace(r'([^(\\w|\\s)]+)', '') # regular expression to remove all matches of non alpha-numeric characters\n",
    "    \n",
    "    #df.title = df.title.str.replace(r'-', '')\n",
    "    #df.title = df.title.str.replace(r':', '')\n",
    "    df.title = df.title.map(lambda x: x.title())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalise the film titles (to help later with matching)\n",
    "agg_sepYr_moveThe_moveA_normed_ml = normlise_title(agg_sepYr_moveThe_moveA_ml.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5198 films with multiple titles in movielens\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>movieId</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>titles_len</th>\n",
       "      <th>title1</th>\n",
       "      <th>title2</th>\n",
       "      <th>title3</th>\n",
       "      <th>title4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28916</th>\n",
       "      <td>Horror</td>\n",
       "      <td>78084.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.888889</td>\n",
       "      <td>1980</td>\n",
       "      <td>4</td>\n",
       "      <td>The Anthropophagus The Grim Reaper</td>\n",
       "      <td>Antropophagus</td>\n",
       "      <td>Man Beast</td>\n",
       "      <td>Savage Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7363</th>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>53835.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.203704</td>\n",
       "      <td>1954</td>\n",
       "      <td>3</td>\n",
       "      <td>Journey To Italy</td>\n",
       "      <td>Viaggio In Italia</td>\n",
       "      <td>Voyage To Italy</td>\n",
       "      <td>Voyage In Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>Drama|War</td>\n",
       "      <td>45899.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1971</td>\n",
       "      <td>3</td>\n",
       "      <td>Trial Of The Road</td>\n",
       "      <td>Checkup On The Roads</td>\n",
       "      <td>Checkpoint</td>\n",
       "      <td>Proverka Na Dorogakh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18878</th>\n",
       "      <td>Comedy|Crime|Drama</td>\n",
       "      <td>68411.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1944</td>\n",
       "      <td>3</td>\n",
       "      <td>Black Magic</td>\n",
       "      <td>Meeting At Midnight</td>\n",
       "      <td>Charlie Chan In Meeting At Midnight</td>\n",
       "      <td>Charlie Chan In Black Magic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30166</th>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>105794.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>1997</td>\n",
       "      <td>3</td>\n",
       "      <td>Another Nine And A Half Weeks</td>\n",
       "      <td>Love In Paris</td>\n",
       "      <td>9 12 Weeks Ii</td>\n",
       "      <td>Another 9 12 Weeks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   genres   movieId  num_ratings    rating  year  titles_len  \\\n",
       "28916              Horror   78084.0          9.0  4.888889  1980           4   \n",
       "7363        Drama|Romance   53835.0         54.0  7.203704  1954           3   \n",
       "1335            Drama|War   45899.0          9.0  8.000000  1971           3   \n",
       "18878  Comedy|Crime|Drama   68411.0          6.0  6.166667  1944           3   \n",
       "30166       Drama|Romance  105794.0          9.0  4.444444  1997           3   \n",
       "\n",
       "                                   title1                title2  \\\n",
       "28916  The Anthropophagus The Grim Reaper         Antropophagus   \n",
       "7363                     Journey To Italy     Viaggio In Italia   \n",
       "1335                    Trial Of The Road  Checkup On The Roads   \n",
       "18878                         Black Magic   Meeting At Midnight   \n",
       "30166       Another Nine And A Half Weeks         Love In Paris   \n",
       "\n",
       "                                    title3                       title4  \n",
       "28916                            Man Beast                Savage Island  \n",
       "7363                       Voyage To Italy              Voyage In Italy  \n",
       "1335                            Checkpoint         Proverka Na Dorogakh  \n",
       "18878  Charlie Chan In Meeting At Midnight  Charlie Chan In Black Magic  \n",
       "30166                        9 12 Weeks Ii           Another 9 12 Weeks  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the multiple alternative film titles in () from movie lens into separate columns\n",
    "df = agg_sepYr_moveThe_moveA_normed_ml.copy()\n",
    "df['title'] = df['title'].str.replace('(A.K.A. )', '') # get rid of extraneous 'A.K.A' text\n",
    "df['titles'] = df['title'].str.findall(r'\\(([^()]+)\\)') # regular expression to find all matches of strings inside parentheses ()\n",
    "df['titles_len'] = df['titles'].map(lambda x: len(x))\n",
    "\n",
    "#Get the first title (not in parentheses)\n",
    "df['title1'] = df['title'].str.extract(r'(\\A[^()]+) \\(') # regular expression to match from the start of the string to first (\n",
    "df.loc[df['title1'].isnull(), 'title1'] = df.loc[df['title1'].isnull(), 'title']\n",
    "\n",
    "# Add separate columns for each alternative title (maximum of 3 alternative titles allowed)\n",
    "# Starting from title2 to title4\n",
    "df['title2'] = pd.np.nan\n",
    "df['title3'] = pd.np.nan\n",
    "df['title4'] = pd.np.nan\n",
    "for i in range(2,5):\n",
    "    df.loc[df['titles_len'] >= i - 1, 'title%s'%i] = df['titles'].map(lambda x: x[i - 2] if len(x) >= i - 1 else pd.np.nan)\n",
    "    \n",
    "#Clean up dataframe by removing now extraneous columns\n",
    "df = df.drop(['title', 'titles', 'has_the', 'has_a'], axis = 1)\n",
    "    \n",
    "#Save and show results\n",
    "agg_sepYr_moveThe_moveA_normed_sepTitles_ml = df\n",
    "print('There are %s films with multiple titles in movielens'%len(df[df['title2'].notnull()]))\n",
    "df.sort_values(by = 'titles_len', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3580847 entries, 0 to 3580846\n",
      "Data columns (total 7 columns):\n",
      "title        object\n",
      "year         int64\n",
      "name         object\n",
      "type         object\n",
      "character    object\n",
      "n            float64\n",
      "index        int64\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 218.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Data: IMDB\n",
    "# Read in IMDB Data\n",
    "cst_im = pd.read_csv(data_dir +'/IMDB/pycon-pandas-tutorial-master/data/cast.csv')\n",
    "mov_im = pd.read_csv(data_dir +'/IMDB/pycon-pandas-tutorial-master/data/titles.csv')\n",
    "\n",
    "# Create data frame with titles and films, it and with id 'index'\n",
    "mov_im.reset_index(inplace=True)\n",
    "mov_cst_im = cst_im.merge(mov_im)\n",
    "\n",
    "mov_cst_im.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalise the film titles (to help later with matching)\n",
    "mov_normed_im = normlise_title(mov_im.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3331 imdb title with roman numerals removed\n",
      "There are 0 imdb titles with two or more (\n",
      "There are 522 alternative titles added\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>im_title</th>\n",
       "      <th>year</th>\n",
       "      <th>im_title1</th>\n",
       "      <th>im_title2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Passing</td>\n",
       "      <td>1985</td>\n",
       "      <td>The Passing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Kothewali</td>\n",
       "      <td>2000</td>\n",
       "      <td>Kothewali</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nemuri Kyoshiro Manji Giri</td>\n",
       "      <td>1969</td>\n",
       "      <td>Nemuri Kyoshiro Manji Giri</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Goose On The Loose</td>\n",
       "      <td>2006</td>\n",
       "      <td>Goose On The Loose</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Parizhskaya Drama</td>\n",
       "      <td>1983</td>\n",
       "      <td>Parizhskaya Drama</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                    im_title  year                   im_title1  \\\n",
       "0      0                 The Passing  1985                 The Passing   \n",
       "1      1                   Kothewali  2000                   Kothewali   \n",
       "2      2  Nemuri Kyoshiro Manji Giri  1969  Nemuri Kyoshiro Manji Giri   \n",
       "3      3          Goose On The Loose  2006          Goose On The Loose   \n",
       "4      4           Parizhskaya Drama  1983           Parizhskaya Drama   \n",
       "\n",
       "  im_title2  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data: IMDB\n",
    "# Fix inserted roman numbers, and separate multiple titles to im_title1 and im_title2\n",
    "df = mov_normed_im.copy()\n",
    "\n",
    "roman_numerals_brackets = r' \\([ixvIXV]+\\)' # re for extracting bracket roman numerals from titles\n",
    "\n",
    "# print some stats for what will be removed.\n",
    "print('There are %s imdb title with roman numerals removed' % len(df[df['title'].str.contains(roman_numerals_brackets)]))\n",
    "print('There are %s imdb titles with two or more (' %len(df[df['title'].str.contains(r'\\w\\(\\w\\(')]))\n",
    "\n",
    "# remove roman numberals from titles\n",
    "df['title'] = df['title'].str.replace(roman_numerals_brackets, '') \n",
    "\n",
    "# Seaprate title into im_title1 and im_title2\n",
    "df['im_title1'] = df['title'].str.extract(r'(\\A[^()]+) \\(') # match from the start of the string to first (\n",
    "df['im_title2'] = df['title'].str.extract(r'\\w \\(([^()]+)\\)$') # match item within bracksets, at the end of string\n",
    "df.loc[df['im_title1'].isnull(), 'im_title1'] = df[df['im_title1'].isnull()]['title'] # for those that dont match the 2 above (ie only one title)\n",
    "\n",
    "# Rename title to avoid confusion down the line when merging with im\n",
    "df = df.rename(columns = {'title':'im_title'}) \n",
    "\n",
    "# Print how much alternative titles have been found\n",
    "print('There are %s alternative titles added' % len(df[df['im_title2'].notnull()]))\n",
    "\n",
    " # Display results of changed multiple name titles\n",
    "mov_im_titles_fixed = df\n",
    "df[df['im_title2'].notnull()].head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Will match x, with the best 'close_match' in list 'lst',\n",
    "# extending difflib's get_close_matches to get the type of matches desired\n",
    "# - will return nan instead of [] for no matches\n",
    "import difflib\n",
    "def get_best_match(x, lst, cutoff):\n",
    "    if type(x) != str:\n",
    "        return pd.np.nan\n",
    "    #print(x)\n",
    "    #print(lst)\n",
    "    ans = difflib.get_close_matches(x, lst, cutoff = cutoff)\n",
    "    if len(ans) == 0:\n",
    "        return pd.np.nan\n",
    "    else:\n",
    "        return ans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAY REMOVE THIS AS IT PRODUCES ALOT OF FALSE POSITIVES, OR MAKE IT SUCH THAT IT CAN ONLY MATCH ON FULL WORDS AT THE START\n",
    "\n",
    "# Will match x with first value in list 'lst', where x is starts with the same start of the string of any list element\n",
    "# or vice-versa, \n",
    "# To avoid too many false matches, make sure each word is > 4 chars in length\n",
    "# e.g. x = 'Star Wars' and lst = ['Star Wars episode 4'] will return 'Star Wars: episode 4'\n",
    "# Will return nan for no match\n",
    "def get_starts_with_match(x, lst):\n",
    "    if type(x) != str:\n",
    "        return pd.np.nan\n",
    "    for s in list(lst):\n",
    "        if type(s) != str:\n",
    "            return pd.np.nan\n",
    "        if (s.startswith(x) | x.startswith(s)) & (len(x) >= 4) & (len(s) >= 4):\n",
    "            return s\n",
    "    return pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Will match x with first value in list 'lst', where words of x is contained within the string of any list element\n",
    "# or vice-cersa, the string of the list element has words all contained within x\n",
    "# e.g. x = 'Il Buono Il Brutto Il Cattivo' and lst = ['Buono Il Brutto Il Cattivo Il'] will return 'Buono Il Brutto Il Cattivo Il'\n",
    "# Will return nan for no match\n",
    "def get_word_subset_match(x, lst):\n",
    "    if type(x) != str:\n",
    "        return pd.np.nan\n",
    "    x = x.split(' ')\n",
    "    for s in list(lst):\n",
    "        y = s.split(' ')\n",
    "        if (set(x) <= set(y)) | (set(y) <= set(x)):\n",
    "            return s\n",
    "    return pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buono Il Brutto Il Cattivo Il'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. x = 'Il Buono Il Brutto Il Cattivo' and lst = ['Buono Il Brutto Il Cattivo Il'] will return 'Buono Il Brutto Il Cattivo Il'\n",
    "# Will return nan for no match\n",
    "x = 'Buono Il Brutto Il Cattivo'\n",
    "lst = ['Buono Il Brutto Il Cattivo Il']\n",
    "get_word_subset_match(x, lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create variables for imdb and movielens databases herafter (for brevity)\n",
    "im = mov_im_titles_fixed # Movies from IMDB database (clean)\n",
    "ml = agg_sepYr_moveThe_moveA_normed_sepTitles_ml # Movies from MovieLens database (clean)\n",
    "con_flds = ['title', 'year'] # the most common connection fields between IMDB and Movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>im_title</th>\n",
       "      <th>year</th>\n",
       "      <th>im_title1</th>\n",
       "      <th>im_title2</th>\n",
       "      <th>prev_year</th>\n",
       "      <th>next_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Passing</td>\n",
       "      <td>1985</td>\n",
       "      <td>The Passing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Kothewali</td>\n",
       "      <td>2000</td>\n",
       "      <td>Kothewali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nemuri Kyoshiro Manji Giri</td>\n",
       "      <td>1969</td>\n",
       "      <td>Nemuri Kyoshiro Manji Giri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1968</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Goose On The Loose</td>\n",
       "      <td>2006</td>\n",
       "      <td>Goose On The Loose</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Parizhskaya Drama</td>\n",
       "      <td>1983</td>\n",
       "      <td>Parizhskaya Drama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1982</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                    im_title  year                   im_title1  \\\n",
       "0      0                 The Passing  1985                 The Passing   \n",
       "1      1                   Kothewali  2000                   Kothewali   \n",
       "2      2  Nemuri Kyoshiro Manji Giri  1969  Nemuri Kyoshiro Manji Giri   \n",
       "3      3          Goose On The Loose  2006          Goose On The Loose   \n",
       "4      4           Parizhskaya Drama  1983           Parizhskaya Drama   \n",
       "\n",
       "  im_title2  prev_year  next_year  \n",
       "0       NaN       1984       1986  \n",
       "1       NaN       1999       2001  \n",
       "2       NaN       1968       1970  \n",
       "3       NaN       2005       2007  \n",
       "4       NaN       1982       1984  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add prev and next years to dataset to help for better matching.\n",
    "im['prev_year'] = im['year'] - 1\n",
    "im['next_year'] = im['year'] + 1\n",
    "im.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10018 exact title matches on title1 with im_title1 year\n",
      "214 exact title matches on title1 with im_title1 prev_year\n",
      "334 exact title matches on title1 with im_title1 next_year\n",
      "1099 exact title matches on title2 with im_title1 year\n",
      "18 exact title matches on title2 with im_title1 prev_year\n",
      "29 exact title matches on title2 with im_title1 next_year\n",
      "46 exact title matches on title3 with im_title1 year\n",
      "1 exact title matches on title3 with im_title1 prev_year\n",
      "1 exact title matches on title3 with im_title1 next_year\n",
      "0 exact title matches on title4 with im_title1 year\n",
      "0 exact title matches on title4 with im_title1 prev_year\n",
      "0 exact title matches on title4 with im_title1 next_year\n",
      "4 exact title matches on title1 with im_title2 year\n",
      "1 exact title matches on title1 with im_title2 prev_year\n",
      "0 exact title matches on title1 with im_title2 next_year\n",
      "9 exact title matches on title2 with im_title2 year\n",
      "0 exact title matches on title2 with im_title2 prev_year\n",
      "0 exact title matches on title2 with im_title2 next_year\n",
      "0 exact title matches on title3 with im_title2 year\n",
      "0 exact title matches on title3 with im_title2 prev_year\n",
      "0 exact title matches on title3 with im_title2 next_year\n",
      "0 exact title matches on title4 with im_title2 year\n",
      "0 exact title matches on title4 with im_title2 prev_year\n",
      "0 exact title matches on title4 with im_title2 next_year\n",
      "380 duplicate matches have been removed (ie match on a title and two or more of: year, prev_year, next_year)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>movieId</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>titles_len</th>\n",
       "      <th>title1</th>\n",
       "      <th>title2</th>\n",
       "      <th>title3</th>\n",
       "      <th>title4</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>im_title1</th>\n",
       "      <th>im_title2</th>\n",
       "      <th>match_on</th>\n",
       "      <th>title_match_type</th>\n",
       "      <th>year_match_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action|Crime</td>\n",
       "      <td>146327.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>Cant Change The Meeting Place</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crime|Drama</td>\n",
       "      <td>318.0</td>\n",
       "      <td>77887.0</td>\n",
       "      <td>8.883421</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64328.0</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>title1</td>\n",
       "      <td>exact</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crime|Drama</td>\n",
       "      <td>858.0</td>\n",
       "      <td>49846.0</td>\n",
       "      <td>8.707278</td>\n",
       "      <td>1972</td>\n",
       "      <td>0</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180450.0</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>NaN</td>\n",
       "      <td>title1</td>\n",
       "      <td>exact</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(no genres listed)</td>\n",
       "      <td>147330.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>Sherlock Holmes And Dr Watson Acquaintance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "      <td>50.0</td>\n",
       "      <td>53195.0</td>\n",
       "      <td>8.637973</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>The Usual Suspects</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30856.0</td>\n",
       "      <td>The Usual Suspects</td>\n",
       "      <td>The Usual Suspects</td>\n",
       "      <td>NaN</td>\n",
       "      <td>title1</td>\n",
       "      <td>exact</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   genres   movieId  num_ratings    rating  year  titles_len  \\\n",
       "0            Action|Crime  146327.0         20.0  8.900000  1979           0   \n",
       "1             Crime|Drama     318.0      77887.0  8.883421  1994           0   \n",
       "2             Crime|Drama     858.0      49846.0  8.707278  1972           0   \n",
       "3      (no genres listed)  147330.0         10.0  8.700000  1979           0   \n",
       "4  Crime|Mystery|Thriller      50.0      53195.0  8.637973  1995           0   \n",
       "\n",
       "                                       title1 title2 title3 title4     index  \\\n",
       "0               Cant Change The Meeting Place    NaN    NaN    NaN       NaN   \n",
       "1                    The Shawshank Redemption    NaN    NaN    NaN   64328.0   \n",
       "2                               The Godfather    NaN    NaN    NaN  180450.0   \n",
       "3  Sherlock Holmes And Dr Watson Acquaintance    NaN    NaN    NaN       NaN   \n",
       "4                          The Usual Suspects    NaN    NaN    NaN   30856.0   \n",
       "\n",
       "                      title                 im_title1 im_title2 match_on  \\\n",
       "0                       NaN                       NaN       NaN      NaN   \n",
       "1  The Shawshank Redemption  The Shawshank Redemption       NaN   title1   \n",
       "2             The Godfather             The Godfather       NaN   title1   \n",
       "3                       NaN                       NaN       NaN      NaN   \n",
       "4        The Usual Suspects        The Usual Suspects       NaN   title1   \n",
       "\n",
       "  title_match_type year_match_on  \n",
       "0              NaN           NaN  \n",
       "1            exact          year  \n",
       "2            exact          year  \n",
       "3              NaN           NaN  \n",
       "4            exact          year  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data: MovieLens & IMDB\n",
    "\n",
    "# Parameters for filtering out films\n",
    "min_num_ratings = 10\n",
    "min_rating = 4\n",
    "min_year = 1965\n",
    "\n",
    "# Filter out films with few ratings\n",
    "ml = ml[ml['num_ratings'] >= min_num_ratings]\n",
    "\n",
    "# Filter out films with poor rating\n",
    "ml = ml[ml['rating'] >= min_rating]\n",
    "\n",
    "#Filter out old films\n",
    "ml = ml[ml['year'] >= min_year]\n",
    "im = im[im['year'] >= min_year]\n",
    "\n",
    "# Merge MovieLens and IMDB dataframes together on title and year for exact match\n",
    "# Starting from title1 and working up to title4 in movielens\n",
    "# And similarly, starting from im_title1 then going to im_title2\n",
    "df = pd.DataFrame()\n",
    "films_all = pd.DataFrame()\n",
    "for im_title in ['im_title1', 'im_title2']:\n",
    "    for i in range (1, 5):\n",
    "\n",
    "        # Iterate through year, prev_year and next_year of imdb to find matches \n",
    "        # prev_year and next_year are in case year is off by 1 between imdb and movielens\n",
    "        for yr in ['year', 'prev_year', 'next_year']:\n",
    "            df = ml.merge(im[im[im_title].notnull()], left_on = ['title%s' %i, 'year'], right_on = [im_title, yr], how = 'inner')\n",
    "            df['title'] = df['title%s' %i]\n",
    "            df['match_on'] = 'title%s' %i # indicate which title (title1 - title4) a match was found\n",
    "            df['title_match_type'] = 'exact' # indicate that the exact title was matched\n",
    "            df['year_match_on'] = yr # indicate if the year was matched correctly (year), or match on prev/next year\n",
    "            print('%s exact title matches on title%s with %s %s' %(len(df), i, im_title, yr))\n",
    "            films_all = films_all.append(df)\n",
    "            \n",
    "# Remove duplicate matches - ie films that match on a title two of more of: year, prev_year, next_year.\n",
    "# Will keep match by (exact year) 'year' by default\n",
    "cnt = len(films_all)\n",
    "films_all = films_all.sort_values(by = ['movieId', 'year_match_on'], ascending = [True, False]).drop_duplicates(subset = 'movieId')\n",
    "print('%s duplicate matches have been removed (ie match on a title and two or more of: year, prev_year, next_year)' % (cnt - len(films_all)))\n",
    "    \n",
    "# Add these matched films, to set of all movielens films. (Films not yet match from movielens to imdb, but be where 'index' = NaN)\n",
    "films_all = ml.merge(films_all[['movieId', 'index', 'title', 'im_title1', 'im_title2', 'match_on', 'title_match_type', 'year_match_on']], how = 'left')\n",
    "films_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>im_title</th>\n",
       "      <th>year</th>\n",
       "      <th>im_title1</th>\n",
       "      <th>im_title2</th>\n",
       "      <th>prev_year</th>\n",
       "      <th>next_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Passing</td>\n",
       "      <td>1985</td>\n",
       "      <td>The Passing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Kothewali</td>\n",
       "      <td>2000</td>\n",
       "      <td>Kothewali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nemuri Kyoshiro Manji Giri</td>\n",
       "      <td>1969</td>\n",
       "      <td>Nemuri Kyoshiro Manji Giri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1968</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Goose On The Loose</td>\n",
       "      <td>2006</td>\n",
       "      <td>Goose On The Loose</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Parizhskaya Drama</td>\n",
       "      <td>1983</td>\n",
       "      <td>Parizhskaya Drama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1982</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                    im_title  year                   im_title1  \\\n",
       "0      0                 The Passing  1985                 The Passing   \n",
       "1      1                   Kothewali  2000                   Kothewali   \n",
       "2      2  Nemuri Kyoshiro Manji Giri  1969  Nemuri Kyoshiro Manji Giri   \n",
       "3      3          Goose On The Loose  2006          Goose On The Loose   \n",
       "4      4           Parizhskaya Drama  1983           Parizhskaya Drama   \n",
       "\n",
       "  im_title2  prev_year  next_year  \n",
       "0       NaN       1984       1986  \n",
       "1       NaN       1999       2001  \n",
       "2       NaN       1968       1970  \n",
       "3       NaN       2005       2007  \n",
       "4       NaN       1982       1984  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data: IMDB\n",
    "\n",
    "# Find films in IMDB whose titles are not yet matched with movielens data, store im_mm\n",
    "df = films_all\n",
    "df = df[df['index'].notnull()]\n",
    "im_mm = im.merge(df[['index', 'movieId']], how = 'left')\n",
    "im_mm[im_mm['movieId'].isnull()]\n",
    "im_mm.drop(['movieId'], axis = 1, inplace = True)\n",
    "im_mm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For this row, return the first non-null value when starting from title1_close_match\n",
    "# and going up to title4_close_match\n",
    "def get_close_title_match(row):\n",
    "    for i in range(1, 5):\n",
    "        if pd.isnull(row['title%s_close_match' %i]) == False:\n",
    "            return row['title%s_close_match' %i]\n",
    "    return pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For this row, return the title name (e.g. title1) of the first non-null value when starting from\n",
    "# title1_close_match and going up to title4_close_match\n",
    "def get_match_on(row):\n",
    "    for i in range(1, 5):\n",
    "        if pd.isnull(row['title%s_close_match' %i]) == False:\n",
    "            return 'title%s'%i\n",
    "    return pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update title with close matches, starting from title1_close_match and working right\n",
    "# Indicate details from the combination c:\n",
    "# - column match_on which title column it matched\n",
    "# - match_type that it was 'close' match (as opposed to 'exact')\n",
    "# - year field matched on\n",
    "# close_match_type can be a string of of the following:\n",
    "# - difflib - using difflib's get_close_matches and taking first value\n",
    "# - contains_match - (as explained in method get_contains_match above)\n",
    "# - word_subset_match - (as explained in method word_subset_match)\n",
    "def update_close_match_title_and_year_fld(df, close_match_type, combo):\n",
    "    \n",
    "    # Filter for all of the new matches\n",
    "    ftr = no_title_for_year(df, combo['year']) & has_title_close_match(df)\n",
    "    \n",
    "    # Update the fields for the new matches\n",
    "    df.loc[ftr, 'title'] = df.loc[ftr].apply(lambda row: get_close_title_match(row), axis = 1)\n",
    "    df.loc[ftr, 'title_match_type'] = 'close'\n",
    "    df.loc[ftr, 'match_on'] = df.loc[ftr].apply(lambda row: get_match_on(row), axis = 1)\n",
    "    df.loc[ftr, 'year_match_on'] = combo['year_fld']\n",
    "    df.loc[ftr, 'close_match_type'] = close_match_type\n",
    "    \n",
    "    # Print the new matches that are found and their details\n",
    "    movielens_titles = len( df[ftr] )\n",
    "    imdb_titles = len(im_mm[im_mm['year'] == combo['year']])\n",
    "    close_matches = len(df[ ftr & df[combo['title_cm_fld']].notnull() ])\n",
    "    if close_matches:\n",
    "        print('From %s movielens & %s imdb titles- %s %s %ses for movielens year %s & imdbs %s' \n",
    "        % (movielens_titles, imdb_titles, close_matches, close_match_type,\n",
    "           combo['title_cm_fld'], combo['year'], combo['year_fld']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_title_close_match(df):\n",
    "    return df['title1_close_match'].notnull()|df['title2_close_match'].notnull()|df['title3_close_match'].notnull()|df['title4_close_match'].notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return filter for all rows where there is no title, for year 'year'\n",
    "def no_title_for_year(df, year):\n",
    "    return df['title'].isnull() & (df['year'] == year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Return filter for all rows where there is no title, for year 'year'\n",
    "def has_title_for_year(df, year):\n",
    "    return df['title'].notnull() & (df['year'] == year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generator for iterating over title field names: zipped titlei & titlei_close_match for i in [1, 4]\n",
    "# nested by all film years in movielens\n",
    "# nested by ['year'] if exact_year parameters is True, else ['prev_year', 'next_year']\n",
    "# Yields a dictionary containing:\n",
    "# title_fld : 'titlei' for i in [1, 4]\n",
    "# title_cm_fld : 'titlei' for i in [1, 4]\n",
    "# year : film year in movielens\n",
    "# year_fld : either 'year', 'prev_year' or 'next_year'\n",
    "from itertools import product\n",
    "def titlefields_filmyears_yearfields(exact_year = True):\n",
    "    stream = product(zip(['title%s'%i for i in range(1, 5) ], ['title%s_close_match'%i for i in range(1, 5) ]), \n",
    "                     range(min(ml['year']), max(ml['year'])+1),\n",
    "                     ['year'] if exact_year else ['prev_year', 'next_year'])\n",
    "    for x in stream:\n",
    "        result = {}\n",
    "        result['title_fld'] = x[0][0]\n",
    "        result['title_cm_fld'] = x[0][1]\n",
    "        result['year'] = x[1]\n",
    "        result['year_fld'] = x[2]\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For iterating through movielens years and finding close matches on titles1 - title4\n",
    "# df - the dataframe to be modified\n",
    "# exact_year - if True will need year's to line up, if False will only use prev_year or next_year\n",
    "# (for speed its best to run this once first on True, then send a smaller list to df and use False)\n",
    "def find_close_matches_on_movielens_titles(df, exact_year = True):\n",
    "                \n",
    "    # Iterate over all combinations, combo of: [title[1-4], title_close_match[1-4]]\n",
    "    # with all years of movielens films AND\n",
    "    # with all year field names if applicable (['year'] for exact_year, otherwise ['prev_year', 'next_year'])\n",
    "    for combo in titlefields_filmyears_yearfields(exact_year):\n",
    "        \n",
    "        # Try both im_title1 and im_title2\n",
    "        for im_title in ['im_title1', 'im_title2']:\n",
    "            \n",
    "            # List of im films to use as potential matches for movielens films\n",
    "            im_films = im_mm[(im_mm[combo['year_fld']] == combo['year'])&im_mm[im_title].notnull()][im_title]\n",
    "        \n",
    "            # Using difflib's get_close_matches...\n",
    "            # Find closest match for film from the i-th title field for this year\n",
    "            # I match found, update fields 'title', 'title_match_type', 'year_match_on', 'match_type','close_match_type'\n",
    "            ftr = no_title_for_year(df, combo['year'])\n",
    "            df.loc[ftr, combo['title_cm_fld']] = df.loc[ftr, combo['title_fld']].map(\n",
    "                lambda x: get_best_match(x, im_films, cutoff = 0.9))\n",
    "            update_close_match_title_and_year_fld(df, 'difflib', combo)\n",
    "\n",
    "            # Using my get_contains_match...\n",
    "            # Find closest match for film from the i-th title field for this year\n",
    "            # I match found, update fields 'title', 'title_match_type', 'year_match_on', 'match_type','close_match_type'\n",
    "            ftr = no_title_for_year(df, combo['year'])\n",
    "            df.loc[ftr, combo['title_cm_fld']] = df.loc[ftr, combo['title_fld']].map(\n",
    "                lambda x: get_starts_with_match(x, im_films))\n",
    "            update_close_match_title_and_year_fld(df, 'startswith', combo)\n",
    "            \n",
    "            # Using my get_subset_match...\n",
    "            # Find closest match for film from the i-th title field for this year\n",
    "            # I match found, update fields 'title', 'title_match_type', 'year_match_on', 'match_type','close_match_type'\n",
    "            ftr = no_title_for_year(df, combo['year'])\n",
    "            df.loc[ftr, combo['title_cm_fld']] = df.loc[ftr, combo['title_fld']].map(\n",
    "                lambda x: get_word_subset_match(x, im_films))\n",
    "            update_close_match_title_and_year_fld(df, 'wordsubset', combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run same iteration as above titlefields_filmyears_yearfields, but for get_contains_match\n",
    "# Or maybe modify the above code, so that get_best_match can be chagned dynamically - this could be slower however than doing in stages..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run same iteration as above titlefields_filmyears_yearfields, but for get_subset_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for combo in titlefields_filmyears_yearfields():\n",
    "#     # Try both im_title1 and im_title2\n",
    "#     for im_title in ['im_title1', 'im_title2']:\n",
    "#         print('%s %s' %(combo, im_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15087 entries, 0 to 15086\n",
      "Data columns (total 17 columns):\n",
      "genres              15087 non-null object\n",
      "movieId             15087 non-null float64\n",
      "num_ratings         15087 non-null float64\n",
      "rating              15087 non-null float64\n",
      "year                15087 non-null int64\n",
      "titles_len          15087 non-null int64\n",
      "title1              15087 non-null object\n",
      "title2              2511 non-null object\n",
      "title3              128 non-null object\n",
      "title4              6 non-null object\n",
      "index               11394 non-null float64\n",
      "title               11394 non-null object\n",
      "im_title1           11394 non-null object\n",
      "im_title2           15 non-null object\n",
      "match_on            11394 non-null object\n",
      "title_match_type    11394 non-null object\n",
      "year_match_on       11394 non-null object\n",
      "dtypes: float64(4), int64(2), object(11)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>movieId</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>titles_len</th>\n",
       "      <th>title1</th>\n",
       "      <th>title2</th>\n",
       "      <th>title3</th>\n",
       "      <th>title4</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>im_title1</th>\n",
       "      <th>im_title2</th>\n",
       "      <th>match_on</th>\n",
       "      <th>title_match_type</th>\n",
       "      <th>year_match_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action|Crime</td>\n",
       "      <td>146327.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>Cant Change The Meeting Place</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(no genres listed)</td>\n",
       "      <td>147330.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>Sherlock Holmes And Dr Watson Acquaintance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(no genres listed)</td>\n",
       "      <td>142115.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.566667</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>The Blue Planet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adventure|Children|Comedy|Drama</td>\n",
       "      <td>139620.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.565217</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>Everythings Gonna Be Great</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Action|Fantasy|Mystery</td>\n",
       "      <td>140737.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.561644</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>The Lost Room</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            genres   movieId  num_ratings    rating  year  \\\n",
       "0                     Action|Crime  146327.0         20.0  8.900000  1979   \n",
       "3               (no genres listed)  147330.0         10.0  8.700000  1979   \n",
       "7               (no genres listed)  142115.0         30.0  8.566667  2001   \n",
       "8  Adventure|Children|Comedy|Drama  139620.0         23.0  8.565217  1998   \n",
       "9           Action|Fantasy|Mystery  140737.0         73.0  8.561644  2006   \n",
       "\n",
       "   titles_len                                      title1 title2 title3  \\\n",
       "0           0               Cant Change The Meeting Place    NaN    NaN   \n",
       "3           0  Sherlock Holmes And Dr Watson Acquaintance    NaN    NaN   \n",
       "7           0                             The Blue Planet    NaN    NaN   \n",
       "8           0                  Everythings Gonna Be Great    NaN    NaN   \n",
       "9           0                               The Lost Room    NaN    NaN   \n",
       "\n",
       "  title4  index title im_title1 im_title2 match_on title_match_type  \\\n",
       "0    NaN    NaN   NaN       NaN       NaN      NaN              NaN   \n",
       "3    NaN    NaN   NaN       NaN       NaN      NaN              NaN   \n",
       "7    NaN    NaN   NaN       NaN       NaN      NaN              NaN   \n",
       "8    NaN    NaN   NaN       NaN       NaN      NaN              NaN   \n",
       "9    NaN    NaN   NaN       NaN       NaN      NaN              NaN   \n",
       "\n",
       "  year_match_on  \n",
       "0           NaN  \n",
       "3           NaN  \n",
       "7           NaN  \n",
       "8           NaN  \n",
       "9           NaN  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_mm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 2 movielens & 1741 imdb titles- 2 difflib title1_close_matches for movielens year 1965 & imdbs year\n",
      "From 1 movielens & 1741 imdb titles- 1 startswith title1_close_matches for movielens year 1965 & imdbs year\n",
      "From 1 movielens & 1741 imdb titles- 1 wordsubset title1_close_matches for movielens year 1965 & imdbs year\n",
      "From 3 movielens & 1837 imdb titles- 3 startswith title1_close_matches for movielens year 1966 & imdbs year\n",
      "From 2 movielens & 1837 imdb titles- 2 wordsubset title1_close_matches for movielens year 1966 & imdbs year\n",
      "From 1 movielens & 1840 imdb titles- 1 wordsubset title1_close_matches for movielens year 1967 & imdbs year\n",
      "From 2 movielens & 1981 imdb titles- 2 difflib title1_close_matches for movielens year 1968 & imdbs year\n",
      "From 1 movielens & 1981 imdb titles- 1 wordsubset title1_close_matches for movielens year 1968 & imdbs year\n",
      "From 2 movielens & 2149 imdb titles- 2 difflib title1_close_matches for movielens year 1969 & imdbs year\n",
      "From 1 movielens & 2109 imdb titles- 1 difflib title1_close_matches for movielens year 1970 & imdbs year\n",
      "From 3 movielens & 2109 imdb titles- 3 wordsubset title1_close_matches for movielens year 1970 & imdbs year\n",
      "From 1 movielens & 1928 imdb titles- 1 difflib title1_close_matches for movielens year 1971 & imdbs year\n",
      "From 4 movielens & 1928 imdb titles- 4 wordsubset title1_close_matches for movielens year 1971 & imdbs year\n",
      "From 1 movielens & 1984 imdb titles- 1 startswith title1_close_matches for movielens year 1972 & imdbs year\n",
      "From 1 movielens & 1984 imdb titles- 1 wordsubset title1_close_matches for movielens year 1972 & imdbs year\n",
      "From 1 movielens & 1857 imdb titles- 1 difflib title1_close_matches for movielens year 1973 & imdbs year\n",
      "From 4 movielens & 1857 imdb titles- 4 wordsubset title1_close_matches for movielens year 1973 & imdbs year\n",
      "From 1 movielens & 1933 imdb titles- 1 difflib title1_close_matches for movielens year 1974 & imdbs year\n",
      "From 1 movielens & 1933 imdb titles- 1 wordsubset title1_close_matches for movielens year 1974 & imdbs year\n",
      "From 2 movielens & 1737 imdb titles- 2 startswith title1_close_matches for movielens year 1976 & imdbs year\n",
      "From 2 movielens & 1685 imdb titles- 2 startswith title1_close_matches for movielens year 1977 & imdbs year\n",
      "From 1 movielens & 1685 imdb titles- 1 wordsubset title1_close_matches for movielens year 1977 & imdbs year\n",
      "From 2 movielens & 1766 imdb titles- 2 difflib title1_close_matches for movielens year 1978 & imdbs year\n",
      "From 2 movielens & 1766 imdb titles- 2 wordsubset title1_close_matches for movielens year 1978 & imdbs year\n",
      "From 2 movielens & 1828 imdb titles- 2 wordsubset title1_close_matches for movielens year 1979 & imdbs year\n",
      "From 2 movielens & 1783 imdb titles- 2 difflib title1_close_matches for movielens year 1980 & imdbs year\n",
      "From 3 movielens & 1783 imdb titles- 3 startswith title1_close_matches for movielens year 1980 & imdbs year\n",
      "From 7 movielens & 1783 imdb titles- 7 wordsubset title1_close_matches for movielens year 1980 & imdbs year\n",
      "From 4 movielens & 1869 imdb titles- 4 difflib title1_close_matches for movielens year 1981 & imdbs year\n",
      "From 1 movielens & 1869 imdb titles- 1 startswith title1_close_matches for movielens year 1981 & imdbs year\n",
      "From 7 movielens & 1869 imdb titles- 7 wordsubset title1_close_matches for movielens year 1981 & imdbs year\n",
      "From 3 movielens & 1913 imdb titles- 3 difflib title1_close_matches for movielens year 1982 & imdbs year\n",
      "From 6 movielens & 1913 imdb titles- 6 wordsubset title1_close_matches for movielens year 1982 & imdbs year\n",
      "From 1 movielens & 1930 imdb titles- 1 difflib title1_close_matches for movielens year 1983 & imdbs year\n",
      "From 8 movielens & 1930 imdb titles- 8 wordsubset title1_close_matches for movielens year 1983 & imdbs year\n",
      "From 2 movielens & 1914 imdb titles- 2 startswith title1_close_matches for movielens year 1984 & imdbs year\n",
      "From 3 movielens & 1914 imdb titles- 3 wordsubset title1_close_matches for movielens year 1984 & imdbs year\n",
      "From 1 movielens & 1957 imdb titles- 1 difflib title1_close_matches for movielens year 1985 & imdbs year\n",
      "From 2 movielens & 1957 imdb titles- 2 startswith title1_close_matches for movielens year 1985 & imdbs year\n",
      "From 3 movielens & 1957 imdb titles- 3 wordsubset title1_close_matches for movielens year 1985 & imdbs year\n",
      "From 3 movielens & 2047 imdb titles- 3 difflib title1_close_matches for movielens year 1986 & imdbs year\n",
      "From 2 movielens & 2047 imdb titles- 2 startswith title1_close_matches for movielens year 1986 & imdbs year\n",
      "From 2 movielens & 2047 imdb titles- 2 wordsubset title1_close_matches for movielens year 1986 & imdbs year\n",
      "From 1 movielens & 2198 imdb titles- 1 difflib title1_close_matches for movielens year 1987 & imdbs year\n",
      "From 3 movielens & 2198 imdb titles- 3 wordsubset title1_close_matches for movielens year 1987 & imdbs year\n",
      "From 1 movielens & 2198 imdb titles- 1 wordsubset title1_close_matches for movielens year 1987 & imdbs year\n",
      "From 3 movielens & 2289 imdb titles- 3 difflib title1_close_matches for movielens year 1988 & imdbs year\n",
      "From 2 movielens & 2289 imdb titles- 2 startswith title1_close_matches for movielens year 1988 & imdbs year\n",
      "From 3 movielens & 2289 imdb titles- 3 wordsubset title1_close_matches for movielens year 1988 & imdbs year\n",
      "From 2 movielens & 2227 imdb titles- 2 difflib title1_close_matches for movielens year 1989 & imdbs year\n",
      "From 2 movielens & 2227 imdb titles- 2 startswith title1_close_matches for movielens year 1989 & imdbs year\n",
      "From 2 movielens & 2227 imdb titles- 2 wordsubset title1_close_matches for movielens year 1989 & imdbs year\n",
      "From 1 movielens & 2227 imdb titles- 1 wordsubset title1_close_matches for movielens year 1989 & imdbs year\n",
      "From 4 movielens & 2283 imdb titles- 4 difflib title1_close_matches for movielens year 1990 & imdbs year\n",
      "From 4 movielens & 2283 imdb titles- 4 wordsubset title1_close_matches for movielens year 1990 & imdbs year\n",
      "From 3 movielens & 2238 imdb titles- 3 difflib title1_close_matches for movielens year 1991 & imdbs year\n",
      "From 2 movielens & 2238 imdb titles- 2 wordsubset title1_close_matches for movielens year 1991 & imdbs year\n",
      "From 1 movielens & 2148 imdb titles- 1 difflib title1_close_matches for movielens year 1992 & imdbs year\n",
      "From 1 movielens & 2148 imdb titles- 1 startswith title1_close_matches for movielens year 1992 & imdbs year\n",
      "From 3 movielens & 2148 imdb titles- 3 wordsubset title1_close_matches for movielens year 1992 & imdbs year\n",
      "From 4 movielens & 2021 imdb titles- 4 difflib title1_close_matches for movielens year 1993 & imdbs year\n",
      "From 4 movielens & 2021 imdb titles- 4 wordsubset title1_close_matches for movielens year 1993 & imdbs year\n",
      "From 2 movielens & 2066 imdb titles- 2 startswith title1_close_matches for movielens year 1994 & imdbs year\n",
      "From 5 movielens & 2066 imdb titles- 5 wordsubset title1_close_matches for movielens year 1994 & imdbs year\n",
      "From 2 movielens & 2081 imdb titles- 2 difflib title1_close_matches for movielens year 1995 & imdbs year\n",
      "From 2 movielens & 2081 imdb titles- 2 startswith title1_close_matches for movielens year 1995 & imdbs year\n",
      "From 3 movielens & 2081 imdb titles- 3 wordsubset title1_close_matches for movielens year 1995 & imdbs year\n",
      "From 1 movielens & 2081 imdb titles- 1 wordsubset title1_close_matches for movielens year 1995 & imdbs year\n",
      "From 3 movielens & 2103 imdb titles- 3 startswith title1_close_matches for movielens year 1996 & imdbs year\n",
      "From 9 movielens & 2103 imdb titles- 9 wordsubset title1_close_matches for movielens year 1996 & imdbs year\n",
      "From 4 movielens & 2301 imdb titles- 4 difflib title1_close_matches for movielens year 1997 & imdbs year\n",
      "From 1 movielens & 2301 imdb titles- 1 startswith title1_close_matches for movielens year 1997 & imdbs year\n",
      "From 7 movielens & 2301 imdb titles- 7 wordsubset title1_close_matches for movielens year 1997 & imdbs year\n",
      "From 1 movielens & 2381 imdb titles- 1 difflib title1_close_matches for movielens year 1998 & imdbs year\n",
      "From 6 movielens & 2381 imdb titles- 6 startswith title1_close_matches for movielens year 1998 & imdbs year\n",
      "From 6 movielens & 2381 imdb titles- 6 wordsubset title1_close_matches for movielens year 1998 & imdbs year\n",
      "From 2 movielens & 2488 imdb titles- 2 difflib title1_close_matches for movielens year 1999 & imdbs year\n",
      "From 2 movielens & 2488 imdb titles- 2 startswith title1_close_matches for movielens year 1999 & imdbs year\n",
      "From 8 movielens & 2488 imdb titles- 8 wordsubset title1_close_matches for movielens year 1999 & imdbs year\n",
      "From 3 movielens & 2726 imdb titles- 3 difflib title1_close_matches for movielens year 2000 & imdbs year\n",
      "From 9 movielens & 2726 imdb titles- 9 startswith title1_close_matches for movielens year 2000 & imdbs year\n",
      "From 10 movielens & 2726 imdb titles- 10 wordsubset title1_close_matches for movielens year 2000 & imdbs year\n",
      "From 1 movielens & 2834 imdb titles- 1 difflib title1_close_matches for movielens year 2001 & imdbs year\n",
      "From 5 movielens & 2834 imdb titles- 5 startswith title1_close_matches for movielens year 2001 & imdbs year\n",
      "From 11 movielens & 2834 imdb titles- 11 wordsubset title1_close_matches for movielens year 2001 & imdbs year\n",
      "From 1 movielens & 2834 imdb titles- 1 wordsubset title1_close_matches for movielens year 2001 & imdbs year\n",
      "From 1 movielens & 2950 imdb titles- 1 difflib title1_close_matches for movielens year 2002 & imdbs year\n",
      "From 12 movielens & 2950 imdb titles- 12 startswith title1_close_matches for movielens year 2002 & imdbs year\n",
      "From 10 movielens & 2950 imdb titles- 10 wordsubset title1_close_matches for movielens year 2002 & imdbs year\n",
      "From 1 movielens & 3109 imdb titles- 1 difflib title1_close_matches for movielens year 2003 & imdbs year\n",
      "From 10 movielens & 3109 imdb titles- 10 startswith title1_close_matches for movielens year 2003 & imdbs year\n",
      "From 19 movielens & 3109 imdb titles- 19 wordsubset title1_close_matches for movielens year 2003 & imdbs year\n",
      "From 1 movielens & 3440 imdb titles- 1 difflib title1_close_matches for movielens year 2004 & imdbs year\n",
      "From 10 movielens & 3440 imdb titles- 10 startswith title1_close_matches for movielens year 2004 & imdbs year\n",
      "From 15 movielens & 3440 imdb titles- 15 wordsubset title1_close_matches for movielens year 2004 & imdbs year\n",
      "From 6 movielens & 3931 imdb titles- 6 difflib title1_close_matches for movielens year 2005 & imdbs year\n",
      "From 11 movielens & 3931 imdb titles- 11 startswith title1_close_matches for movielens year 2005 & imdbs year\n",
      "From 14 movielens & 3931 imdb titles- 14 wordsubset title1_close_matches for movielens year 2005 & imdbs year\n",
      "From 2 movielens & 4182 imdb titles- 2 difflib title1_close_matches for movielens year 2006 & imdbs year\n",
      "From 13 movielens & 4182 imdb titles- 13 startswith title1_close_matches for movielens year 2006 & imdbs year\n",
      "From 23 movielens & 4182 imdb titles- 23 wordsubset title1_close_matches for movielens year 2006 & imdbs year\n",
      "From 1 movielens & 4338 imdb titles- 1 difflib title1_close_matches for movielens year 2007 & imdbs year\n",
      "From 8 movielens & 4338 imdb titles- 8 startswith title1_close_matches for movielens year 2007 & imdbs year\n",
      "From 35 movielens & 4338 imdb titles- 35 wordsubset title1_close_matches for movielens year 2007 & imdbs year\n",
      "From 6 movielens & 5010 imdb titles- 6 difflib title1_close_matches for movielens year 2008 & imdbs year\n",
      "From 15 movielens & 5010 imdb titles- 15 startswith title1_close_matches for movielens year 2008 & imdbs year\n",
      "From 33 movielens & 5010 imdb titles- 33 wordsubset title1_close_matches for movielens year 2008 & imdbs year\n",
      "From 5 movielens & 6016 imdb titles- 5 difflib title1_close_matches for movielens year 2009 & imdbs year\n",
      "From 19 movielens & 6016 imdb titles- 19 startswith title1_close_matches for movielens year 2009 & imdbs year\n",
      "From 51 movielens & 6016 imdb titles- 51 wordsubset title1_close_matches for movielens year 2009 & imdbs year\n",
      "From 7 movielens & 6261 imdb titles- 7 difflib title1_close_matches for movielens year 2010 & imdbs year\n",
      "From 19 movielens & 6261 imdb titles- 19 startswith title1_close_matches for movielens year 2010 & imdbs year\n",
      "From 58 movielens & 6261 imdb titles- 58 wordsubset title1_close_matches for movielens year 2010 & imdbs year\n",
      "From 5 movielens & 6858 imdb titles- 5 difflib title1_close_matches for movielens year 2011 & imdbs year\n",
      "From 18 movielens & 6858 imdb titles- 18 startswith title1_close_matches for movielens year 2011 & imdbs year\n",
      "From 49 movielens & 6858 imdb titles- 49 wordsubset title1_close_matches for movielens year 2011 & imdbs year\n",
      "From 5 movielens & 7248 imdb titles- 5 difflib title1_close_matches for movielens year 2012 & imdbs year\n",
      "From 13 movielens & 7248 imdb titles- 13 startswith title1_close_matches for movielens year 2012 & imdbs year\n",
      "From 28 movielens & 7248 imdb titles- 28 wordsubset title1_close_matches for movielens year 2012 & imdbs year\n",
      "From 12 movielens & 7652 imdb titles- 12 difflib title1_close_matches for movielens year 2013 & imdbs year\n",
      "From 11 movielens & 7652 imdb titles- 11 startswith title1_close_matches for movielens year 2013 & imdbs year\n",
      "From 35 movielens & 7652 imdb titles- 35 wordsubset title1_close_matches for movielens year 2013 & imdbs year\n",
      "From 7 movielens & 8069 imdb titles- 7 difflib title1_close_matches for movielens year 2014 & imdbs year\n",
      "From 22 movielens & 8069 imdb titles- 22 startswith title1_close_matches for movielens year 2014 & imdbs year\n",
      "From 39 movielens & 8069 imdb titles- 39 wordsubset title1_close_matches for movielens year 2014 & imdbs year\n",
      "From 1 movielens & 8686 imdb titles- 1 difflib title1_close_matches for movielens year 2015 & imdbs year\n",
      "From 8 movielens & 8686 imdb titles- 8 startswith title1_close_matches for movielens year 2015 & imdbs year\n",
      "From 23 movielens & 8686 imdb titles- 23 wordsubset title1_close_matches for movielens year 2015 & imdbs year\n",
      "From 1 movielens & 14554 imdb titles- 1 wordsubset title1_close_matches for movielens year 2016 & imdbs year\n",
      "From 2 movielens & 1741 imdb titles- 2 wordsubset title2_close_matches for movielens year 1965 & imdbs year\n",
      "From 3 movielens & 1837 imdb titles- 3 wordsubset title2_close_matches for movielens year 1966 & imdbs year\n",
      "From 1 movielens & 1840 imdb titles- 1 startswith title2_close_matches for movielens year 1967 & imdbs year\n",
      "From 2 movielens & 1840 imdb titles- 2 wordsubset title2_close_matches for movielens year 1967 & imdbs year\n",
      "From 1 movielens & 1981 imdb titles- 1 wordsubset title2_close_matches for movielens year 1968 & imdbs year\n",
      "From 2 movielens & 2149 imdb titles- 2 wordsubset title2_close_matches for movielens year 1969 & imdbs year\n",
      "From 1 movielens & 2109 imdb titles- 1 difflib title2_close_matches for movielens year 1970 & imdbs year\n",
      "From 4 movielens & 2109 imdb titles- 4 wordsubset title2_close_matches for movielens year 1970 & imdbs year\n",
      "From 3 movielens & 1928 imdb titles- 3 wordsubset title2_close_matches for movielens year 1971 & imdbs year\n",
      "From 1 movielens & 1984 imdb titles- 1 difflib title2_close_matches for movielens year 1972 & imdbs year\n",
      "From 1 movielens & 1984 imdb titles- 1 wordsubset title2_close_matches for movielens year 1972 & imdbs year\n",
      "From 1 movielens & 1857 imdb titles- 1 difflib title2_close_matches for movielens year 1973 & imdbs year\n",
      "From 1 movielens & 1857 imdb titles- 1 wordsubset title2_close_matches for movielens year 1973 & imdbs year\n",
      "From 3 movielens & 1933 imdb titles- 3 wordsubset title2_close_matches for movielens year 1974 & imdbs year\n",
      "From 1 movielens & 1724 imdb titles- 1 wordsubset title2_close_matches for movielens year 1975 & imdbs year\n",
      "From 1 movielens & 1737 imdb titles- 1 difflib title2_close_matches for movielens year 1976 & imdbs year\n",
      "From 2 movielens & 1737 imdb titles- 2 wordsubset title2_close_matches for movielens year 1976 & imdbs year\n",
      "From 2 movielens & 1685 imdb titles- 2 difflib title2_close_matches for movielens year 1977 & imdbs year\n",
      "From 3 movielens & 1685 imdb titles- 3 wordsubset title2_close_matches for movielens year 1977 & imdbs year\n",
      "From 2 movielens & 1828 imdb titles- 2 wordsubset title2_close_matches for movielens year 1979 & imdbs year\n",
      "From 1 movielens & 1783 imdb titles- 1 difflib title2_close_matches for movielens year 1980 & imdbs year\n",
      "From 4 movielens & 1869 imdb titles- 4 wordsubset title2_close_matches for movielens year 1981 & imdbs year\n",
      "From 1 movielens & 1913 imdb titles- 1 difflib title2_close_matches for movielens year 1982 & imdbs year\n",
      "From 8 movielens & 1913 imdb titles- 8 wordsubset title2_close_matches for movielens year 1982 & imdbs year\n",
      "From 1 movielens & 1930 imdb titles- 1 difflib title2_close_matches for movielens year 1983 & imdbs year\n",
      "From 2 movielens & 1930 imdb titles- 2 wordsubset title2_close_matches for movielens year 1983 & imdbs year\n",
      "From 1 movielens & 1914 imdb titles- 1 difflib title2_close_matches for movielens year 1984 & imdbs year\n",
      "From 2 movielens & 1914 imdb titles- 2 wordsubset title2_close_matches for movielens year 1984 & imdbs year\n",
      "From 2 movielens & 1957 imdb titles- 2 wordsubset title2_close_matches for movielens year 1985 & imdbs year\n",
      "From 1 movielens & 2047 imdb titles- 1 startswith title2_close_matches for movielens year 1986 & imdbs year\n",
      "From 2 movielens & 2047 imdb titles- 2 wordsubset title2_close_matches for movielens year 1986 & imdbs year\n",
      "From 1 movielens & 2198 imdb titles- 1 difflib title2_close_matches for movielens year 1987 & imdbs year\n",
      "From 1 movielens & 2198 imdb titles- 1 wordsubset title2_close_matches for movielens year 1987 & imdbs year\n",
      "From 1 movielens & 2289 imdb titles- 1 difflib title2_close_matches for movielens year 1988 & imdbs year\n",
      "From 1 movielens & 2289 imdb titles- 1 wordsubset title2_close_matches for movielens year 1988 & imdbs year\n",
      "From 2 movielens & 2227 imdb titles- 2 wordsubset title2_close_matches for movielens year 1989 & imdbs year\n",
      "From 1 movielens & 2283 imdb titles- 1 wordsubset title2_close_matches for movielens year 1990 & imdbs year\n",
      "From 1 movielens & 2238 imdb titles- 1 difflib title2_close_matches for movielens year 1991 & imdbs year\n",
      "From 1 movielens & 2238 imdb titles- 1 wordsubset title2_close_matches for movielens year 1991 & imdbs year\n",
      "From 2 movielens & 2148 imdb titles- 2 wordsubset title2_close_matches for movielens year 1992 & imdbs year\n",
      "From 2 movielens & 2021 imdb titles- 2 difflib title2_close_matches for movielens year 1993 & imdbs year\n",
      "From 2 movielens & 2021 imdb titles- 2 wordsubset title2_close_matches for movielens year 1993 & imdbs year\n",
      "From 2 movielens & 2066 imdb titles- 2 difflib title2_close_matches for movielens year 1994 & imdbs year\n",
      "From 4 movielens & 2066 imdb titles- 4 wordsubset title2_close_matches for movielens year 1994 & imdbs year\n",
      "From 1 movielens & 2081 imdb titles- 1 difflib title2_close_matches for movielens year 1995 & imdbs year\n",
      "From 7 movielens & 2081 imdb titles- 7 wordsubset title2_close_matches for movielens year 1995 & imdbs year\n",
      "From 5 movielens & 2103 imdb titles- 5 difflib title2_close_matches for movielens year 1996 & imdbs year\n",
      "From 3 movielens & 2103 imdb titles- 3 wordsubset title2_close_matches for movielens year 1996 & imdbs year\n",
      "From 3 movielens & 2301 imdb titles- 3 difflib title2_close_matches for movielens year 1997 & imdbs year\n",
      "From 2 movielens & 2301 imdb titles- 2 wordsubset title2_close_matches for movielens year 1997 & imdbs year\n",
      "From 2 movielens & 2381 imdb titles- 2 difflib title2_close_matches for movielens year 1998 & imdbs year\n",
      "From 1 movielens & 2381 imdb titles- 1 startswith title2_close_matches for movielens year 1998 & imdbs year\n",
      "From 4 movielens & 2381 imdb titles- 4 wordsubset title2_close_matches for movielens year 1998 & imdbs year\n",
      "From 1 movielens & 2488 imdb titles- 1 startswith title2_close_matches for movielens year 1999 & imdbs year\n",
      "From 4 movielens & 2488 imdb titles- 4 wordsubset title2_close_matches for movielens year 1999 & imdbs year\n",
      "From 2 movielens & 2726 imdb titles- 2 difflib title2_close_matches for movielens year 2000 & imdbs year\n",
      "From 10 movielens & 2726 imdb titles- 10 wordsubset title2_close_matches for movielens year 2000 & imdbs year\n",
      "From 1 movielens & 2834 imdb titles- 1 difflib title2_close_matches for movielens year 2001 & imdbs year\n",
      "From 9 movielens & 2834 imdb titles- 9 wordsubset title2_close_matches for movielens year 2001 & imdbs year\n",
      "From 1 movielens & 2950 imdb titles- 1 difflib title2_close_matches for movielens year 2002 & imdbs year\n",
      "From 8 movielens & 2950 imdb titles- 8 wordsubset title2_close_matches for movielens year 2002 & imdbs year\n",
      "From 1 movielens & 3109 imdb titles- 1 difflib title2_close_matches for movielens year 2003 & imdbs year\n",
      "From 5 movielens & 3109 imdb titles- 5 wordsubset title2_close_matches for movielens year 2003 & imdbs year\n",
      "From 4 movielens & 3440 imdb titles- 4 difflib title2_close_matches for movielens year 2004 & imdbs year\n",
      "From 5 movielens & 3440 imdb titles- 5 wordsubset title2_close_matches for movielens year 2004 & imdbs year\n",
      "From 6 movielens & 3931 imdb titles- 6 wordsubset title2_close_matches for movielens year 2005 & imdbs year\n",
      "From 7 movielens & 4182 imdb titles- 7 wordsubset title2_close_matches for movielens year 2006 & imdbs year\n",
      "From 3 movielens & 4338 imdb titles- 3 difflib title2_close_matches for movielens year 2007 & imdbs year\n",
      "From 7 movielens & 4338 imdb titles- 7 wordsubset title2_close_matches for movielens year 2007 & imdbs year\n",
      "From 1 movielens & 5010 imdb titles- 1 difflib title2_close_matches for movielens year 2008 & imdbs year\n",
      "From 1 movielens & 5010 imdb titles- 1 startswith title2_close_matches for movielens year 2008 & imdbs year\n",
      "From 3 movielens & 5010 imdb titles- 3 wordsubset title2_close_matches for movielens year 2008 & imdbs year\n",
      "From 1 movielens & 6016 imdb titles- 1 startswith title2_close_matches for movielens year 2009 & imdbs year\n",
      "From 6 movielens & 6016 imdb titles- 6 wordsubset title2_close_matches for movielens year 2009 & imdbs year\n",
      "From 2 movielens & 6261 imdb titles- 2 difflib title2_close_matches for movielens year 2010 & imdbs year\n",
      "From 1 movielens & 6261 imdb titles- 1 startswith title2_close_matches for movielens year 2010 & imdbs year\n",
      "From 2 movielens & 6261 imdb titles- 2 wordsubset title2_close_matches for movielens year 2010 & imdbs year\n",
      "From 1 movielens & 6858 imdb titles- 1 startswith title2_close_matches for movielens year 2011 & imdbs year\n",
      "From 2 movielens & 6858 imdb titles- 2 wordsubset title2_close_matches for movielens year 2011 & imdbs year\n",
      "From 1 movielens & 7248 imdb titles- 1 startswith title2_close_matches for movielens year 2012 & imdbs year\n",
      "From 6 movielens & 7248 imdb titles- 6 wordsubset title2_close_matches for movielens year 2012 & imdbs year\n",
      "From 6 movielens & 7652 imdb titles- 6 wordsubset title2_close_matches for movielens year 2013 & imdbs year\n",
      "From 2 movielens & 8069 imdb titles- 2 wordsubset title2_close_matches for movielens year 2014 & imdbs year\n",
      "From 1 movielens & 8069 imdb titles- 1 wordsubset title2_close_matches for movielens year 2014 & imdbs year\n",
      "From 1 movielens & 1930 imdb titles- 1 wordsubset title3_close_matches for movielens year 1983 & imdbs year\n",
      "From 1 movielens & 2198 imdb titles- 1 wordsubset title3_close_matches for movielens year 1987 & imdbs year\n",
      "From 1 movielens & 2066 imdb titles- 1 difflib title3_close_matches for movielens year 1994 & imdbs year\n",
      "From 1 movielens & 2103 imdb titles- 1 difflib title3_close_matches for movielens year 1996 & imdbs year\n",
      "From 1 movielens & 2381 imdb titles- 1 difflib title3_close_matches for movielens year 1998 & imdbs year\n",
      "From 1 movielens & 2834 imdb titles- 1 wordsubset title3_close_matches for movielens year 2001 & imdbs year\n",
      "From 1 movielens & 5010 imdb titles- 1 wordsubset title3_close_matches for movielens year 2008 & imdbs year\n",
      "From 1 movielens & 1869 imdb titles- 1 wordsubset title4_close_matches for movielens year 1981 & imdbs year\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>movieId</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>titles_len</th>\n",
       "      <th>title1</th>\n",
       "      <th>title2</th>\n",
       "      <th>title3</th>\n",
       "      <th>title4</th>\n",
       "      <th>...</th>\n",
       "      <th>im_title1</th>\n",
       "      <th>im_title2</th>\n",
       "      <th>match_on</th>\n",
       "      <th>title_match_type</th>\n",
       "      <th>year_match_on</th>\n",
       "      <th>title1_close_match</th>\n",
       "      <th>title2_close_match</th>\n",
       "      <th>title3_close_match</th>\n",
       "      <th>title4_close_match</th>\n",
       "      <th>close_match_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Action|Fantasy|Mystery</td>\n",
       "      <td>140737.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.561644</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>The Lost Room</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>title1</td>\n",
       "      <td>close</td>\n",
       "      <td>year</td>\n",
       "      <td>The Lost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>startswith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>139090.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>The U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>title1</td>\n",
       "      <td>close</td>\n",
       "      <td>year</td>\n",
       "      <td>The Uhoh Show</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>startswith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>260.0</td>\n",
       "      <td>67092.0</td>\n",
       "      <td>8.316103</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>Star Wars Episode Iv  A New Hope</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>title1</td>\n",
       "      <td>close</td>\n",
       "      <td>year</td>\n",
       "      <td>Star Wars</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>startswith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>110366.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>Jeanmichel Basquiat The Radiant Child</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>title1</td>\n",
       "      <td>close</td>\n",
       "      <td>year</td>\n",
       "      <td>The The The</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>86504.0</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>8.261710</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>Voices From The List</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>title1</td>\n",
       "      <td>close</td>\n",
       "      <td>year</td>\n",
       "      <td>The List</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     genres   movieId  num_ratings    rating  year  \\\n",
       "9    Action|Fantasy|Mystery  140737.0         73.0  8.561644  2006   \n",
       "23              Documentary  139090.0         10.0  8.400000  2009   \n",
       "38  Action|Adventure|Sci-Fi     260.0      67092.0  8.316103  1977   \n",
       "45              Documentary  110366.0         10.0  8.300000  2010   \n",
       "52              Documentary   86504.0       1345.0  8.261710  2004   \n",
       "\n",
       "    titles_len                                 title1 title2 title3 title4  \\\n",
       "9            0                          The Lost Room    NaN    NaN    NaN   \n",
       "23           0                                  The U    NaN    NaN    NaN   \n",
       "38           0       Star Wars Episode Iv  A New Hope    NaN    NaN    NaN   \n",
       "45           0  Jeanmichel Basquiat The Radiant Child    NaN    NaN    NaN   \n",
       "52           0                   Voices From The List    NaN    NaN    NaN   \n",
       "\n",
       "         ...         im_title1 im_title2 match_on title_match_type  \\\n",
       "9        ...               NaN       NaN   title1            close   \n",
       "23       ...               NaN       NaN   title1            close   \n",
       "38       ...               NaN       NaN   title1            close   \n",
       "45       ...               NaN       NaN   title1            close   \n",
       "52       ...               NaN       NaN   title1            close   \n",
       "\n",
       "   year_match_on title1_close_match title2_close_match title3_close_match  \\\n",
       "9           year           The Lost                NaN                NaN   \n",
       "23          year      The Uhoh Show                NaN                NaN   \n",
       "38          year          Star Wars                NaN                NaN   \n",
       "45          year        The The The                NaN                NaN   \n",
       "52          year           The List                NaN                NaN   \n",
       "\n",
       "   title4_close_match close_match_type  \n",
       "9                 NaN       startswith  \n",
       "23                NaN       startswith  \n",
       "38                NaN       startswith  \n",
       "45                NaN       wordsubset  \n",
       "52                NaN       wordsubset  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data: MovieLens & IMDB\n",
    "\n",
    "# Continue modifying the same dataframe\n",
    "df = films_all.copy()\n",
    "\n",
    "# Create new field for each title1 to title4 for close match\n",
    "for i in range(1, 5):\n",
    "    df['title%s_close_match' %i] = pd.np.nan\n",
    "    \n",
    "# Create new field to display which close match technique was used\n",
    "# 'difflib', 'contains_match', 'word_subset'\n",
    "df['close_match_type'] = pd.np.nan\n",
    "\n",
    "find_close_matches_on_movielens_titles(df)\n",
    "#find_close_matches_on_movielens_titles(df, exact_year = False)\n",
    "\n",
    "# Save results\n",
    "films_all_w_cmtitles = df\n",
    "\n",
    "#Show close matches that have been found\n",
    "close_match_ftr = df['title1_close_match'].notnull()|df['title2_close_match'].notnull()|df['title3_close_match'].notnull()|df['title4_close_match'].notnull()\n",
    "df[close_match_ftr].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>im_title1</th>\n",
       "      <th>im_title2</th>\n",
       "      <th>title1</th>\n",
       "      <th>title2</th>\n",
       "      <th>title3</th>\n",
       "      <th>title4</th>\n",
       "      <th>title1_close_match</th>\n",
       "      <th>title2_close_match</th>\n",
       "      <th>title3_close_match</th>\n",
       "      <th>title4_close_match</th>\n",
       "      <th>close_match_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>The The The</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeanmichel Basquiat The Radiant Child</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The The The</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>The List</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Voices From The List</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The List</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Tomorrow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World Of Tomorrow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tomorrow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Il Buono Il Brutto Il Cattivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Good The Bad And The Ugly</td>\n",
       "      <td>Buono Il Brutto Il Cattivo Il</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Il Buono Il Brutto Il Cattivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Das Boot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Boot Das</td>\n",
       "      <td>Boat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Das Boot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>The Hunt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Trials Of Darryl Hunt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Hunt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Boy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Old Boy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Lost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paradise Lost The Child Murders At Robin Hood Hills</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Freedom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Trap What Happened To Our Dream Of Freedom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freedom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Se7En</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seven</td>\n",
       "      <td>Aka Se7En</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Se7En</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Killer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Killer</td>\n",
       "      <td>Die Xue Shuang Xiong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Killer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Il Conformista</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Conformist</td>\n",
       "      <td>Conformista Il</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Il Conformista</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Eternal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Puella Magi Madoka Magica The Movie Part Ii Eternal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eternal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Adventure In Space And Timen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>El Laberinto Del Fauno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pans Labyrinth</td>\n",
       "      <td>Laberinto Del Fauno El</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El Laberinto Del Fauno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ghost In The Shell Stand Alone Complex  The Laughing Man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Earth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>From The Earth To The Moon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Earth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Robert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Jinx The Life And Deaths Of Robert Durst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Robert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Film</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Story Of Film An Odyssey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Film</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Man Named Pearl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winning Time Reggie Miller Vs The New York Knicks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>A Boy Called Hate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hate</td>\n",
       "      <td>Haine La</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Boy Called Hate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Silence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Look Of Silence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Silence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>And Now For Something Completely Different</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Monty Pythons And Now For Something Completely Different</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And Now For Something Completely Different</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Life Of Brian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Monty Pythons Life Of Brian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Life Of Brian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Oh My God</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Louis Ck Oh My God</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oh My God</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Il Postino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Postman</td>\n",
       "      <td>Postino Il</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Il Postino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>La Migliore Offerta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Best Offer</td>\n",
       "      <td>Migliore Offerta La</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>La Migliore Offerta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Direction Home Bob Dylan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Le Cercle Rouge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Cercle Rouge Le</td>\n",
       "      <td>Red Circle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Le Cercle Rouge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14286</th>\n",
       "      <td>Ever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Grumpy Cats Worst Christmas Ever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14387</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High School Musical 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14421</th>\n",
       "      <td>The Movie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gumby The Movie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Movie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14471</th>\n",
       "      <td>Trip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Road Trip Beer Pong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14475</th>\n",
       "      <td>Animal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Batman Unlimited Animal Instincts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Animal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14505</th>\n",
       "      <td>Flight 7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Flight 7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14521</th>\n",
       "      <td>Conversation With The Beast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Beast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conversation With The Beast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14572</th>\n",
       "      <td>Human Highway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neil Young Human Highway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Human Highway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14612</th>\n",
       "      <td>King</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Scorpion King 2 Rise Of A Warrior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>King</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14693</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dragonlance Dragons Of Autumn Twilight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14732</th>\n",
       "      <td>The The The</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lost Boys The Thirst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The The The</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14733</th>\n",
       "      <td>Bloodline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tremors 5 Bloodline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bloodline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14758</th>\n",
       "      <td>Friday The 13Th The Final Chapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday The 13Th Part Iv The Final Chapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday The 13Th The Final Chapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14782</th>\n",
       "      <td>The Killing Machine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Machine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Killing Machine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14799</th>\n",
       "      <td>Hero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marvel Super Hero Adventures Frost Fight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14802</th>\n",
       "      <td>Monster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scoobydoo Curse Of The Lake Monster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Monster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831</th>\n",
       "      <td>Le Notti Del Terrore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burial Ground</td>\n",
       "      <td>Aka Zombie Horror</td>\n",
       "      <td>Aka Zombie 3</td>\n",
       "      <td>Notti Del Terrore Le</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Le Notti Del Terrore</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14887</th>\n",
       "      <td>La Terza Madre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mother Of Tears The Third Mother</td>\n",
       "      <td>Terza Madre La</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>La Terza Madre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14896</th>\n",
       "      <td>Wolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Night Wolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14913</th>\n",
       "      <td>Jason Lives Friday The 13Th Part Vi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday The 13Th Part Vi Jason Lives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Lives Friday The 13Th Part Vi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14962</th>\n",
       "      <td>The The The</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Planet Of The Future</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The The The</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14973</th>\n",
       "      <td>Love</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Revenge Of The Nerds Iv Nerds In Love</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15001</th>\n",
       "      <td>Hello Mary Lou Prom Night Ii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prom Night Ii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello Mary Lou Prom Night Ii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15014</th>\n",
       "      <td>Revenge Of The Drunken Master</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Master</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Revenge Of The Drunken Master</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15027</th>\n",
       "      <td>On</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Return To House On Haunted Hill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>American Girl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Psycho Ii All American Girl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Girl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15045</th>\n",
       "      <td>One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One Direction This Is Us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15067</th>\n",
       "      <td>Lady Killers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National Lampoons Lady Killers</td>\n",
       "      <td>National Lampoons Gold Diggers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lady Killers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15075</th>\n",
       "      <td>Friday The 13Th A New Beginning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday The 13Th Part V A New Beginning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday The 13Th A New Beginning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15086</th>\n",
       "      <td>When Time Ran Out</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The When Time Ran Out</td>\n",
       "      <td>Day The World Ended</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Time Ran Out</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title im_title1 im_title2  \\\n",
       "45                                    The The The       NaN       NaN   \n",
       "52                                       The List       NaN       NaN   \n",
       "61                                       Tomorrow       NaN       NaN   \n",
       "67                  Il Buono Il Brutto Il Cattivo       NaN       NaN   \n",
       "71                                       Das Boot       NaN       NaN   \n",
       "81                                       The Hunt       NaN       NaN   \n",
       "99                                            Boy       NaN       NaN   \n",
       "104                                          Lost       NaN       NaN   \n",
       "114                                       Freedom       NaN       NaN   \n",
       "118                                         Se7En       NaN       NaN   \n",
       "133                                        Killer       NaN       NaN   \n",
       "166                                Il Conformista       NaN       NaN   \n",
       "173                                       Eternal       NaN       NaN   \n",
       "187                                             A       NaN       NaN   \n",
       "227                        El Laberinto Del Fauno       NaN       NaN   \n",
       "239                                                     NaN       NaN   \n",
       "240                                         Earth       NaN       NaN   \n",
       "259                                        Robert       NaN       NaN   \n",
       "262                                          Film       NaN       NaN   \n",
       "265                                             A       NaN       NaN   \n",
       "268                                          Time       NaN       NaN   \n",
       "303                             A Boy Called Hate       NaN       NaN   \n",
       "313                                       Silence       NaN       NaN   \n",
       "317    And Now For Something Completely Different       NaN       NaN   \n",
       "330                                 Life Of Brian       NaN       NaN   \n",
       "336                                     Oh My God       NaN       NaN   \n",
       "363                                    Il Postino       NaN       NaN   \n",
       "392                           La Migliore Offerta       NaN       NaN   \n",
       "411                                          Home       NaN       NaN   \n",
       "441                               Le Cercle Rouge       NaN       NaN   \n",
       "...                                           ...       ...       ...   \n",
       "14286                                        Ever       NaN       NaN   \n",
       "14387                                           2       NaN       NaN   \n",
       "14421                                   The Movie       NaN       NaN   \n",
       "14471                                        Trip       NaN       NaN   \n",
       "14475                                      Animal       NaN       NaN   \n",
       "14505                                 Flight 7500       NaN       NaN   \n",
       "14521                 Conversation With The Beast       NaN       NaN   \n",
       "14572                               Human Highway       NaN       NaN   \n",
       "14612                                        King       NaN       NaN   \n",
       "14693                                    Twilight       NaN       NaN   \n",
       "14732                                 The The The       NaN       NaN   \n",
       "14733                                   Bloodline       NaN       NaN   \n",
       "14758           Friday The 13Th The Final Chapter       NaN       NaN   \n",
       "14782                         The Killing Machine       NaN       NaN   \n",
       "14799                                        Hero       NaN       NaN   \n",
       "14802                                     Monster       NaN       NaN   \n",
       "14831                        Le Notti Del Terrore       NaN       NaN   \n",
       "14887                              La Terza Madre       NaN       NaN   \n",
       "14896                                        Wolf       NaN       NaN   \n",
       "14913         Jason Lives Friday The 13Th Part Vi       NaN       NaN   \n",
       "14962                                 The The The       NaN       NaN   \n",
       "14973                                        Love       NaN       NaN   \n",
       "15001                Hello Mary Lou Prom Night Ii       NaN       NaN   \n",
       "15014               Revenge Of The Drunken Master       NaN       NaN   \n",
       "15027                                          On       NaN       NaN   \n",
       "15037                               American Girl       NaN       NaN   \n",
       "15045                                         One       NaN       NaN   \n",
       "15067                                Lady Killers       NaN       NaN   \n",
       "15075             Friday The 13Th A New Beginning       NaN       NaN   \n",
       "15086                           When Time Ran Out       NaN       NaN   \n",
       "\n",
       "                                                         title1  \\\n",
       "45                        Jeanmichel Basquiat The Radiant Child   \n",
       "52                                         Voices From The List   \n",
       "61                                            World Of Tomorrow   \n",
       "67                                The Good The Bad And The Ugly   \n",
       "71                                                 The Boot Das   \n",
       "81                                    The Trials Of Darryl Hunt   \n",
       "99                                                      Old Boy   \n",
       "104         Paradise Lost The Child Murders At Robin Hood Hills   \n",
       "114              The Trap What Happened To Our Dream Of Freedom   \n",
       "118                                                       Seven   \n",
       "133                                                  The Killer   \n",
       "166                                              The Conformist   \n",
       "173         Puella Magi Madoka Magica The Movie Part Ii Eternal   \n",
       "187                              A Adventure In Space And Timen   \n",
       "227                                              Pans Labyrinth   \n",
       "239    Ghost In The Shell Stand Alone Complex  The Laughing Man   \n",
       "240                                  From The Earth To The Moon   \n",
       "259                The Jinx The Life And Deaths Of Robert Durst   \n",
       "262                                The Story Of Film An Odyssey   \n",
       "265                                           A Man Named Pearl   \n",
       "268           Winning Time Reggie Miller Vs The New York Knicks   \n",
       "303                                                        Hate   \n",
       "313                                         The Look Of Silence   \n",
       "317    Monty Pythons And Now For Something Completely Different   \n",
       "330                                 Monty Pythons Life Of Brian   \n",
       "336                                          Louis Ck Oh My God   \n",
       "363                                                 The Postman   \n",
       "392                                              The Best Offer   \n",
       "411                                 No Direction Home Bob Dylan   \n",
       "441                                         The Cercle Rouge Le   \n",
       "...                                                         ...   \n",
       "14286                          Grumpy Cats Worst Christmas Ever   \n",
       "14387                                     High School Musical 2   \n",
       "14421                                           Gumby The Movie   \n",
       "14471                                       Road Trip Beer Pong   \n",
       "14475                         Batman Unlimited Animal Instincts   \n",
       "14505                                                      7500   \n",
       "14521                                                 The Beast   \n",
       "14572                                  Neil Young Human Highway   \n",
       "14612                     The Scorpion King 2 Rise Of A Warrior   \n",
       "14693                    Dragonlance Dragons Of Autumn Twilight   \n",
       "14732                                      Lost Boys The Thirst   \n",
       "14733                                       Tremors 5 Bloodline   \n",
       "14758                 Friday The 13Th Part Iv The Final Chapter   \n",
       "14782                                               The Machine   \n",
       "14799                  Marvel Super Hero Adventures Frost Fight   \n",
       "14802                       Scoobydoo Curse Of The Lake Monster   \n",
       "14831                                             Burial Ground   \n",
       "14887                          Mother Of Tears The Third Mother   \n",
       "14896                                                Night Wolf   \n",
       "14913                       Friday The 13Th Part Vi Jason Lives   \n",
       "14962                                  The Planet Of The Future   \n",
       "14973                     Revenge Of The Nerds Iv Nerds In Love   \n",
       "15001                                             Prom Night Ii   \n",
       "15014                                                The Master   \n",
       "15027                           Return To House On Haunted Hill   \n",
       "15037                      American Psycho Ii All American Girl   \n",
       "15045                                  One Direction This Is Us   \n",
       "15067                            National Lampoons Lady Killers   \n",
       "15075                    Friday The 13Th Part V A New Beginning   \n",
       "15086                                     The When Time Ran Out   \n",
       "\n",
       "                               title2        title3                title4  \\\n",
       "45                                NaN           NaN                   NaN   \n",
       "52                                NaN           NaN                   NaN   \n",
       "61                                NaN           NaN                   NaN   \n",
       "67      Buono Il Brutto Il Cattivo Il           NaN                   NaN   \n",
       "71                               Boat           NaN                   NaN   \n",
       "81                                NaN           NaN                   NaN   \n",
       "99                                NaN           NaN                   NaN   \n",
       "104                               NaN           NaN                   NaN   \n",
       "114                               NaN           NaN                   NaN   \n",
       "118                         Aka Se7En           NaN                   NaN   \n",
       "133              Die Xue Shuang Xiong           NaN                   NaN   \n",
       "166                    Conformista Il           NaN                   NaN   \n",
       "173                               NaN           NaN                   NaN   \n",
       "187                               NaN           NaN                   NaN   \n",
       "227            Laberinto Del Fauno El           NaN                   NaN   \n",
       "239                               NaN           NaN                   NaN   \n",
       "240                               NaN           NaN                   NaN   \n",
       "259                               NaN           NaN                   NaN   \n",
       "262                               NaN           NaN                   NaN   \n",
       "265                               NaN           NaN                   NaN   \n",
       "268                               NaN           NaN                   NaN   \n",
       "303                          Haine La           NaN                   NaN   \n",
       "313                               NaN           NaN                   NaN   \n",
       "317                               NaN           NaN                   NaN   \n",
       "330                               NaN           NaN                   NaN   \n",
       "336                               NaN           NaN                   NaN   \n",
       "363                        Postino Il           NaN                   NaN   \n",
       "392               Migliore Offerta La           NaN                   NaN   \n",
       "411                               NaN           NaN                   NaN   \n",
       "441                        Red Circle           NaN                   NaN   \n",
       "...                               ...           ...                   ...   \n",
       "14286                             NaN           NaN                   NaN   \n",
       "14387                             NaN           NaN                   NaN   \n",
       "14421                             NaN           NaN                   NaN   \n",
       "14471                             NaN           NaN                   NaN   \n",
       "14475                             NaN           NaN                   NaN   \n",
       "14505                             NaN           NaN                   NaN   \n",
       "14521                             NaN           NaN                   NaN   \n",
       "14572                             NaN           NaN                   NaN   \n",
       "14612                             NaN           NaN                   NaN   \n",
       "14693                             NaN           NaN                   NaN   \n",
       "14732                             NaN           NaN                   NaN   \n",
       "14733                             NaN           NaN                   NaN   \n",
       "14758                             NaN           NaN                   NaN   \n",
       "14782                             NaN           NaN                   NaN   \n",
       "14799                             NaN           NaN                   NaN   \n",
       "14802                             NaN           NaN                   NaN   \n",
       "14831               Aka Zombie Horror  Aka Zombie 3  Notti Del Terrore Le   \n",
       "14887                  Terza Madre La           NaN                   NaN   \n",
       "14896                             NaN           NaN                   NaN   \n",
       "14913                             NaN           NaN                   NaN   \n",
       "14962                             NaN           NaN                   NaN   \n",
       "14973                             NaN           NaN                   NaN   \n",
       "15001                             NaN           NaN                   NaN   \n",
       "15014                             NaN           NaN                   NaN   \n",
       "15027                             NaN           NaN                   NaN   \n",
       "15037                             NaN           NaN                   NaN   \n",
       "15045                             NaN           NaN                   NaN   \n",
       "15067  National Lampoons Gold Diggers           NaN                   NaN   \n",
       "15075                             NaN           NaN                   NaN   \n",
       "15086             Day The World Ended           NaN                   NaN   \n",
       "\n",
       "                               title1_close_match  \\\n",
       "45                                    The The The   \n",
       "52                                       The List   \n",
       "61                                       Tomorrow   \n",
       "67                                            NaN   \n",
       "71                                       Das Boot   \n",
       "81                                       The Hunt   \n",
       "99                                            Boy   \n",
       "104                                          Lost   \n",
       "114                                       Freedom   \n",
       "118                                           NaN   \n",
       "133                                        Killer   \n",
       "166                                           NaN   \n",
       "173                                       Eternal   \n",
       "187                                             A   \n",
       "227                                           NaN   \n",
       "239                                                 \n",
       "240                                         Earth   \n",
       "259                                        Robert   \n",
       "262                                          Film   \n",
       "265                                             A   \n",
       "268                                          Time   \n",
       "303                             A Boy Called Hate   \n",
       "313                                       Silence   \n",
       "317    And Now For Something Completely Different   \n",
       "330                                 Life Of Brian   \n",
       "336                                     Oh My God   \n",
       "363                                           NaN   \n",
       "392                                           NaN   \n",
       "411                                          Home   \n",
       "441                               Le Cercle Rouge   \n",
       "...                                           ...   \n",
       "14286                                        Ever   \n",
       "14387                                           2   \n",
       "14421                                   The Movie   \n",
       "14471                                        Trip   \n",
       "14475                                      Animal   \n",
       "14505                                 Flight 7500   \n",
       "14521                 Conversation With The Beast   \n",
       "14572                               Human Highway   \n",
       "14612                                        King   \n",
       "14693                                    Twilight   \n",
       "14732                                 The The The   \n",
       "14733                                   Bloodline   \n",
       "14758           Friday The 13Th The Final Chapter   \n",
       "14782                         The Killing Machine   \n",
       "14799                                        Hero   \n",
       "14802                                     Monster   \n",
       "14831                                         NaN   \n",
       "14887                                         NaN   \n",
       "14896                                        Wolf   \n",
       "14913         Jason Lives Friday The 13Th Part Vi   \n",
       "14962                                 The The The   \n",
       "14973                                        Love   \n",
       "15001                Hello Mary Lou Prom Night Ii   \n",
       "15014               Revenge Of The Drunken Master   \n",
       "15027                                          On   \n",
       "15037                               American Girl   \n",
       "15045                                         One   \n",
       "15067                                Lady Killers   \n",
       "15075             Friday The 13Th A New Beginning   \n",
       "15086                           When Time Ran Out   \n",
       "\n",
       "                  title2_close_match title3_close_match    title4_close_match  \\\n",
       "45                               NaN                NaN                   NaN   \n",
       "52                               NaN                NaN                   NaN   \n",
       "61                               NaN                NaN                   NaN   \n",
       "67     Il Buono Il Brutto Il Cattivo                NaN                   NaN   \n",
       "71                               NaN                NaN                   NaN   \n",
       "81                               NaN                NaN                   NaN   \n",
       "99                               NaN                NaN                   NaN   \n",
       "104                              NaN                NaN                   NaN   \n",
       "114                              NaN                NaN                   NaN   \n",
       "118                            Se7En                NaN                   NaN   \n",
       "133                              NaN                NaN                   NaN   \n",
       "166                   Il Conformista                NaN                   NaN   \n",
       "173                              NaN                NaN                   NaN   \n",
       "187                              NaN                NaN                   NaN   \n",
       "227           El Laberinto Del Fauno                NaN                   NaN   \n",
       "239                              NaN                NaN                   NaN   \n",
       "240                              NaN                NaN                   NaN   \n",
       "259                              NaN                NaN                   NaN   \n",
       "262                              NaN                NaN                   NaN   \n",
       "265                              NaN                NaN                   NaN   \n",
       "268                              NaN                NaN                   NaN   \n",
       "303                              NaN                NaN                   NaN   \n",
       "313                              NaN                NaN                   NaN   \n",
       "317                              NaN                NaN                   NaN   \n",
       "330                              NaN                NaN                   NaN   \n",
       "336                              NaN                NaN                   NaN   \n",
       "363                       Il Postino                NaN                   NaN   \n",
       "392              La Migliore Offerta                NaN                   NaN   \n",
       "411                              NaN                NaN                   NaN   \n",
       "441                              NaN                NaN                   NaN   \n",
       "...                              ...                ...                   ...   \n",
       "14286                            NaN                NaN                   NaN   \n",
       "14387                            NaN                NaN                   NaN   \n",
       "14421                            NaN                NaN                   NaN   \n",
       "14471                            NaN                NaN                   NaN   \n",
       "14475                            NaN                NaN                   NaN   \n",
       "14505                            NaN                NaN                   NaN   \n",
       "14521                            NaN                NaN                   NaN   \n",
       "14572                            NaN                NaN                   NaN   \n",
       "14612                            NaN                NaN                   NaN   \n",
       "14693                            NaN                NaN                   NaN   \n",
       "14732                            NaN                NaN                   NaN   \n",
       "14733                            NaN                NaN                   NaN   \n",
       "14758                            NaN                NaN                   NaN   \n",
       "14782                            NaN                NaN                   NaN   \n",
       "14799                            NaN                NaN                   NaN   \n",
       "14802                            NaN                NaN                   NaN   \n",
       "14831                            NaN                NaN  Le Notti Del Terrore   \n",
       "14887                 La Terza Madre                NaN                   NaN   \n",
       "14896                            NaN                NaN                   NaN   \n",
       "14913                            NaN                NaN                   NaN   \n",
       "14962                            NaN                NaN                   NaN   \n",
       "14973                            NaN                NaN                   NaN   \n",
       "15001                            NaN                NaN                   NaN   \n",
       "15014                            NaN                NaN                   NaN   \n",
       "15027                            NaN                NaN                   NaN   \n",
       "15037                            NaN                NaN                   NaN   \n",
       "15045                            NaN                NaN                   NaN   \n",
       "15067                            NaN                NaN                   NaN   \n",
       "15075                            NaN                NaN                   NaN   \n",
       "15086                            NaN                NaN                   NaN   \n",
       "\n",
       "      close_match_type  \n",
       "45          wordsubset  \n",
       "52          wordsubset  \n",
       "61          wordsubset  \n",
       "67          wordsubset  \n",
       "71          wordsubset  \n",
       "81          wordsubset  \n",
       "99          wordsubset  \n",
       "104         wordsubset  \n",
       "114         wordsubset  \n",
       "118         wordsubset  \n",
       "133         wordsubset  \n",
       "166         wordsubset  \n",
       "173         wordsubset  \n",
       "187         wordsubset  \n",
       "227         wordsubset  \n",
       "239         wordsubset  \n",
       "240         wordsubset  \n",
       "259         wordsubset  \n",
       "262         wordsubset  \n",
       "265         wordsubset  \n",
       "268         wordsubset  \n",
       "303         wordsubset  \n",
       "313         wordsubset  \n",
       "317         wordsubset  \n",
       "330         wordsubset  \n",
       "336         wordsubset  \n",
       "363         wordsubset  \n",
       "392         wordsubset  \n",
       "411         wordsubset  \n",
       "441         wordsubset  \n",
       "...                ...  \n",
       "14286       wordsubset  \n",
       "14387       wordsubset  \n",
       "14421       wordsubset  \n",
       "14471       wordsubset  \n",
       "14475       wordsubset  \n",
       "14505       wordsubset  \n",
       "14521       wordsubset  \n",
       "14572       wordsubset  \n",
       "14612       wordsubset  \n",
       "14693       wordsubset  \n",
       "14732       wordsubset  \n",
       "14733       wordsubset  \n",
       "14758       wordsubset  \n",
       "14782       wordsubset  \n",
       "14799       wordsubset  \n",
       "14802       wordsubset  \n",
       "14831       wordsubset  \n",
       "14887       wordsubset  \n",
       "14896       wordsubset  \n",
       "14913       wordsubset  \n",
       "14962       wordsubset  \n",
       "14973       wordsubset  \n",
       "15001       wordsubset  \n",
       "15014       wordsubset  \n",
       "15027       wordsubset  \n",
       "15037       wordsubset  \n",
       "15045       wordsubset  \n",
       "15067       wordsubset  \n",
       "15075       wordsubset  \n",
       "15086       wordsubset  \n",
       "\n",
       "[750 rows x 12 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = films_all_w_cmtitles\n",
    "df[df['close_match_type'] == 'wordsubset'][['title', 'im_title1', 'im_title2', 'title1', 'title2', 'title3', 'title4', 'title1_close_match', 'title2_close_match', 'title3_close_match', 'title4_close_match', 'close_match_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_match_type  year_match_on  match_on\n",
       "close             year           title1       361\n",
       "                                 title2        67\n",
       "                                 title3         4\n",
       "exact             next_year      title1       221\n",
       "                                 title2        26\n",
       "                                 title3         1\n",
       "                  prev_year      title1        94\n",
       "                                 title2        13\n",
       "                                 title3         1\n",
       "                  year           title1      9913\n",
       "                                 title2      1079\n",
       "                                 title3        46\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the results of all matches on all titles, exact or close on title and year\n",
    "df = films_all_w_cmtitles\n",
    "df.groupby(['title_match_type', 'year_match_on', 'match_on']).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>movieId</th>\n",
       "      <th>index</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>close_match_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>110366.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>2010</td>\n",
       "      <td>The The The</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>86504.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>8.261710</td>\n",
       "      <td>2004</td>\n",
       "      <td>The List</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Animation|Comedy</td>\n",
       "      <td>148881.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>2015</td>\n",
       "      <td>Tomorrow</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Action|Adventure|Western</td>\n",
       "      <td>1201.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16356.0</td>\n",
       "      <td>8.237100</td>\n",
       "      <td>1966</td>\n",
       "      <td>Il Buono Il Brutto Il Cattivo</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Action|Drama|War</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15108.0</td>\n",
       "      <td>8.212669</td>\n",
       "      <td>1981</td>\n",
       "      <td>Das Boot</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Crime|Documentary</td>\n",
       "      <td>53885.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>2006</td>\n",
       "      <td>The Hunt</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Mystery|Thriller</td>\n",
       "      <td>27773.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8357.0</td>\n",
       "      <td>8.153285</td>\n",
       "      <td>2003</td>\n",
       "      <td>Boy</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>8.147950</td>\n",
       "      <td>1996</td>\n",
       "      <td>Lost</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>89985.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.130435</td>\n",
       "      <td>2007</td>\n",
       "      <td>Freedom</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Mystery|Thriller</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47630.0</td>\n",
       "      <td>8.125446</td>\n",
       "      <td>1995</td>\n",
       "      <td>Se7En</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2955.0</td>\n",
       "      <td>8.104907</td>\n",
       "      <td>1989</td>\n",
       "      <td>Killer</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Drama</td>\n",
       "      <td>2925.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>874.0</td>\n",
       "      <td>8.077803</td>\n",
       "      <td>1970</td>\n",
       "      <td>Il Conformista</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Action|Animation|Horror|Mystery</td>\n",
       "      <td>142452.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>2012</td>\n",
       "      <td>Eternal</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Drama</td>\n",
       "      <td>107130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.060606</td>\n",
       "      <td>2013</td>\n",
       "      <td>A</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Drama|Fantasy|Thriller</td>\n",
       "      <td>48394.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14540.0</td>\n",
       "      <td>8.028886</td>\n",
       "      <td>2006</td>\n",
       "      <td>El Laberinto Del Fauno</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Action|Animation|Crime|Sci-Fi</td>\n",
       "      <td>135456.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8.017857</td>\n",
       "      <td>2005</td>\n",
       "      <td></td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Action|Documentary|Drama|Thriller</td>\n",
       "      <td>27002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>402.0</td>\n",
       "      <td>8.017413</td>\n",
       "      <td>1998</td>\n",
       "      <td>Earth</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>131724.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>522.0</td>\n",
       "      <td>8.003831</td>\n",
       "      <td>2015</td>\n",
       "      <td>Robert</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>127180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2011</td>\n",
       "      <td>Film</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>64418.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2006</td>\n",
       "      <td>A</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>132555.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2010</td>\n",
       "      <td>Time</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Crime|Drama</td>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2455.0</td>\n",
       "      <td>7.976782</td>\n",
       "      <td>1995</td>\n",
       "      <td>A Boy Called Hate</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>114635.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.972222</td>\n",
       "      <td>2014</td>\n",
       "      <td>Silence</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>2788.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6063.0</td>\n",
       "      <td>7.967838</td>\n",
       "      <td>1971</td>\n",
       "      <td>And Now For Something Completely Different</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22569.0</td>\n",
       "      <td>7.953698</td>\n",
       "      <td>1979</td>\n",
       "      <td>Life Of Brian</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>104069.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>585.0</td>\n",
       "      <td>7.950427</td>\n",
       "      <td>2013</td>\n",
       "      <td>Oh My God</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13267.0</td>\n",
       "      <td>7.936157</td>\n",
       "      <td>1994</td>\n",
       "      <td>Il Postino</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>103235.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.0</td>\n",
       "      <td>7.920330</td>\n",
       "      <td>2013</td>\n",
       "      <td>La Migliore Offerta</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>38304.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>778.0</td>\n",
       "      <td>7.911311</td>\n",
       "      <td>2005</td>\n",
       "      <td>Home</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Crime|Thriller</td>\n",
       "      <td>6920.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>422.0</td>\n",
       "      <td>7.895735</td>\n",
       "      <td>1970</td>\n",
       "      <td>Le Cercle Rouge</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14286</th>\n",
       "      <td>Adventure|Children|Comedy</td>\n",
       "      <td>117885.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.789474</td>\n",
       "      <td>2014</td>\n",
       "      <td>Ever</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14387</th>\n",
       "      <td>Comedy|Drama|Musical|Romance</td>\n",
       "      <td>61123.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>443.0</td>\n",
       "      <td>4.720090</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14421</th>\n",
       "      <td>Animation|Children</td>\n",
       "      <td>244.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.0</td>\n",
       "      <td>4.704698</td>\n",
       "      <td>1995</td>\n",
       "      <td>The Movie</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14471</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>74864.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4.671429</td>\n",
       "      <td>2009</td>\n",
       "      <td>Trip</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14475</th>\n",
       "      <td>Animation</td>\n",
       "      <td>132656.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2015</td>\n",
       "      <td>Animal</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14505</th>\n",
       "      <td>Action|Horror|Mystery|Thriller</td>\n",
       "      <td>111856.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.647059</td>\n",
       "      <td>2014</td>\n",
       "      <td>Flight 7500</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14521</th>\n",
       "      <td>Drama|Horror|Thriller</td>\n",
       "      <td>79765.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>1996</td>\n",
       "      <td>Conversation With The Beast</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14572</th>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>6085.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1982</td>\n",
       "      <td>Human Highway</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14612</th>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>94480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.575000</td>\n",
       "      <td>2008</td>\n",
       "      <td>King</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14693</th>\n",
       "      <td>Action|Adventure|Animation|Fantasy</td>\n",
       "      <td>80926.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2008</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14732</th>\n",
       "      <td>Horror|Thriller</td>\n",
       "      <td>81080.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.454545</td>\n",
       "      <td>2010</td>\n",
       "      <td>The The The</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14733</th>\n",
       "      <td>Action|Horror|Sci-Fi</td>\n",
       "      <td>143209.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.454545</td>\n",
       "      <td>2015</td>\n",
       "      <td>Bloodline</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14758</th>\n",
       "      <td>Horror</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1333.0</td>\n",
       "      <td>4.427607</td>\n",
       "      <td>1984</td>\n",
       "      <td>Friday The 13Th The Final Chapter</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14782</th>\n",
       "      <td>Horror|Sci-Fi|Thriller</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>1994</td>\n",
       "      <td>The Killing Machine</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14799</th>\n",
       "      <td>Animation|Fantasy</td>\n",
       "      <td>148976.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>2015</td>\n",
       "      <td>Hero</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14802</th>\n",
       "      <td>Adventure|Children|Comedy|Mystery</td>\n",
       "      <td>85295.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.380952</td>\n",
       "      <td>2010</td>\n",
       "      <td>Monster</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831</th>\n",
       "      <td>Horror</td>\n",
       "      <td>5210.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.350877</td>\n",
       "      <td>1981</td>\n",
       "      <td>Le Notti Del Terrore</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14887</th>\n",
       "      <td>Fantasy|Horror|Thriller</td>\n",
       "      <td>61398.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.275862</td>\n",
       "      <td>2007</td>\n",
       "      <td>La Terza Madre</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14896</th>\n",
       "      <td>Action|Horror</td>\n",
       "      <td>81451.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.272727</td>\n",
       "      <td>2010</td>\n",
       "      <td>Wolf</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14913</th>\n",
       "      <td>Horror</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>4.247278</td>\n",
       "      <td>1986</td>\n",
       "      <td>Jason Lives Friday The 13Th Part Vi</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14962</th>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>104638.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.181818</td>\n",
       "      <td>2010</td>\n",
       "      <td>The The The</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14973</th>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>65740.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.172414</td>\n",
       "      <td>1994</td>\n",
       "      <td>Love</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15001</th>\n",
       "      <td>Horror|Thriller</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.0</td>\n",
       "      <td>4.130159</td>\n",
       "      <td>1987</td>\n",
       "      <td>Hello Mary Lou Prom Night Ii</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15014</th>\n",
       "      <td>Action</td>\n",
       "      <td>2258.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.115385</td>\n",
       "      <td>1984</td>\n",
       "      <td>Revenge Of The Drunken Master</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15027</th>\n",
       "      <td>Horror|Thriller</td>\n",
       "      <td>61314.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>2007</td>\n",
       "      <td>On</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>Comedy|Crime|Horror|Mystery|Thriller</td>\n",
       "      <td>27473.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4.078571</td>\n",
       "      <td>2002</td>\n",
       "      <td>American Girl</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15045</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>104728.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.062500</td>\n",
       "      <td>2013</td>\n",
       "      <td>One</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15067</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>32666.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.014706</td>\n",
       "      <td>2003</td>\n",
       "      <td>Lady Killers</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15075</th>\n",
       "      <td>Horror</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>4.002549</td>\n",
       "      <td>1985</td>\n",
       "      <td>Friday The 13Th A New Beginning</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15086</th>\n",
       "      <td>Action|Adventure</td>\n",
       "      <td>5702.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1980</td>\n",
       "      <td>When Time Ran Out</td>\n",
       "      <td>wordsubset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     genres   movieId  index  num_ratings  \\\n",
       "45                              Documentary  110366.0    NaN         10.0   \n",
       "52                              Documentary   86504.0    NaN       1345.0   \n",
       "61                         Animation|Comedy  148881.0    NaN         12.0   \n",
       "67                 Action|Adventure|Western    1201.0    NaN      16356.0   \n",
       "71                         Action|Drama|War    1233.0    NaN      15108.0   \n",
       "81                        Crime|Documentary   53885.0    NaN         10.0   \n",
       "99                         Mystery|Thriller   27773.0    NaN       8357.0   \n",
       "104                             Documentary    1361.0    NaN       1683.0   \n",
       "114                             Documentary   89985.0    NaN         23.0   \n",
       "118                        Mystery|Thriller      47.0    NaN      47630.0   \n",
       "133             Action|Crime|Drama|Thriller    1218.0    NaN       2955.0   \n",
       "166                                   Drama    2925.0    NaN        874.0   \n",
       "173         Action|Animation|Horror|Mystery  142452.0    NaN         14.0   \n",
       "187                                   Drama  107130.0    NaN         33.0   \n",
       "227                  Drama|Fantasy|Thriller   48394.0    NaN      14540.0   \n",
       "239           Action|Animation|Crime|Sci-Fi  135456.0    NaN         56.0   \n",
       "240       Action|Documentary|Drama|Thriller   27002.0    NaN        402.0   \n",
       "259                             Documentary  131724.0    NaN        522.0   \n",
       "262                             Documentary  127180.0    NaN         34.0   \n",
       "265                             Documentary   64418.0    NaN         18.0   \n",
       "268                             Documentary  132555.0    NaN         13.0   \n",
       "303                             Crime|Drama      97.0    NaN       2455.0   \n",
       "313                             Documentary  114635.0    NaN         36.0   \n",
       "317                                  Comedy    2788.0    NaN       6063.0   \n",
       "330                                  Comedy    1080.0    NaN      22569.0   \n",
       "336                                  Comedy  104069.0    NaN        585.0   \n",
       "363                    Comedy|Drama|Romance      58.0    NaN      13267.0   \n",
       "392                                Thriller  103235.0    NaN        364.0   \n",
       "411                             Documentary   38304.0    NaN        778.0   \n",
       "441                          Crime|Thriller    6920.0    NaN        422.0   \n",
       "...                                     ...       ...    ...          ...   \n",
       "14286             Adventure|Children|Comedy  117885.0    NaN         19.0   \n",
       "14387          Comedy|Drama|Musical|Romance   61123.0    NaN        443.0   \n",
       "14421                    Animation|Children     244.0    NaN        298.0   \n",
       "14471                                Comedy   74864.0    NaN         70.0   \n",
       "14475                             Animation  132656.0    NaN         21.0   \n",
       "14505        Action|Horror|Mystery|Thriller  111856.0    NaN         17.0   \n",
       "14521                 Drama|Horror|Thriller   79765.0    NaN         11.0   \n",
       "14572                          Comedy|Drama    6085.0    NaN         10.0   \n",
       "14612              Action|Adventure|Fantasy   94480.0    NaN         80.0   \n",
       "14693    Action|Adventure|Animation|Fantasy   80926.0    NaN         14.0   \n",
       "14732                       Horror|Thriller   81080.0    NaN         22.0   \n",
       "14733                  Action|Horror|Sci-Fi  143209.0    NaN         22.0   \n",
       "14758                                Horror    1977.0    NaN       1333.0   \n",
       "14782                Horror|Sci-Fi|Thriller    1433.0    NaN         70.0   \n",
       "14799                     Animation|Fantasy  148976.0    NaN         13.0   \n",
       "14802     Adventure|Children|Comedy|Mystery   85295.0    NaN         42.0   \n",
       "14831                                Horror    5210.0    NaN         57.0   \n",
       "14887               Fantasy|Horror|Thriller   61398.0    NaN         29.0   \n",
       "14896                         Action|Horror   81451.0    NaN         11.0   \n",
       "14913                                Horror    1979.0    NaN       1286.0   \n",
       "14962               Action|Adventure|Sci-Fi  104638.0    NaN         11.0   \n",
       "14973                        Comedy|Romance   65740.0    NaN         58.0   \n",
       "15001                       Horror|Thriller    1988.0    NaN        315.0   \n",
       "15014                                Action    2258.0    NaN         52.0   \n",
       "15027                       Horror|Thriller   61314.0    NaN         30.0   \n",
       "15037  Comedy|Crime|Horror|Mystery|Thriller   27473.0    NaN        140.0   \n",
       "15045                           Documentary  104728.0    NaN         16.0   \n",
       "15067                                Comedy   32666.0    NaN         68.0   \n",
       "15075                                Horror    1978.0    NaN       1177.0   \n",
       "15086                      Action|Adventure    5702.0    NaN         10.0   \n",
       "\n",
       "         rating  year                                       title  \\\n",
       "45     8.300000  2010                                 The The The   \n",
       "52     8.261710  2004                                    The List   \n",
       "61     8.250000  2015                                    Tomorrow   \n",
       "67     8.237100  1966               Il Buono Il Brutto Il Cattivo   \n",
       "71     8.212669  1981                                    Das Boot   \n",
       "81     8.200000  2006                                    The Hunt   \n",
       "99     8.153285  2003                                         Boy   \n",
       "104    8.147950  1996                                        Lost   \n",
       "114    8.130435  2007                                     Freedom   \n",
       "118    8.125446  1995                                       Se7En   \n",
       "133    8.104907  1989                                      Killer   \n",
       "166    8.077803  1970                              Il Conformista   \n",
       "173    8.071429  2012                                     Eternal   \n",
       "187    8.060606  2013                                           A   \n",
       "227    8.028886  2006                      El Laberinto Del Fauno   \n",
       "239    8.017857  2005                                               \n",
       "240    8.017413  1998                                       Earth   \n",
       "259    8.003831  2015                                      Robert   \n",
       "262    8.000000  2011                                        Film   \n",
       "265    8.000000  2006                                           A   \n",
       "268    8.000000  2010                                        Time   \n",
       "303    7.976782  1995                           A Boy Called Hate   \n",
       "313    7.972222  2014                                     Silence   \n",
       "317    7.967838  1971  And Now For Something Completely Different   \n",
       "330    7.953698  1979                               Life Of Brian   \n",
       "336    7.950427  2013                                   Oh My God   \n",
       "363    7.936157  1994                                  Il Postino   \n",
       "392    7.920330  2013                         La Migliore Offerta   \n",
       "411    7.911311  2005                                        Home   \n",
       "441    7.895735  1970                             Le Cercle Rouge   \n",
       "...         ...   ...                                         ...   \n",
       "14286  4.789474  2014                                        Ever   \n",
       "14387  4.720090  2007                                           2   \n",
       "14421  4.704698  1995                                   The Movie   \n",
       "14471  4.671429  2009                                        Trip   \n",
       "14475  4.666667  2015                                      Animal   \n",
       "14505  4.647059  2014                                 Flight 7500   \n",
       "14521  4.636364  1996                 Conversation With The Beast   \n",
       "14572  4.600000  1982                               Human Highway   \n",
       "14612  4.575000  2008                                        King   \n",
       "14693  4.500000  2008                                    Twilight   \n",
       "14732  4.454545  2010                                 The The The   \n",
       "14733  4.454545  2015                                   Bloodline   \n",
       "14758  4.427607  1984           Friday The 13Th The Final Chapter   \n",
       "14782  4.400000  1994                         The Killing Machine   \n",
       "14799  4.384615  2015                                        Hero   \n",
       "14802  4.380952  2010                                     Monster   \n",
       "14831  4.350877  1981                        Le Notti Del Terrore   \n",
       "14887  4.275862  2007                              La Terza Madre   \n",
       "14896  4.272727  2010                                        Wolf   \n",
       "14913  4.247278  1986         Jason Lives Friday The 13Th Part Vi   \n",
       "14962  4.181818  2010                                 The The The   \n",
       "14973  4.172414  1994                                        Love   \n",
       "15001  4.130159  1987                Hello Mary Lou Prom Night Ii   \n",
       "15014  4.115385  1984               Revenge Of The Drunken Master   \n",
       "15027  4.100000  2007                                          On   \n",
       "15037  4.078571  2002                               American Girl   \n",
       "15045  4.062500  2013                                         One   \n",
       "15067  4.014706  2003                                Lady Killers   \n",
       "15075  4.002549  1985             Friday The 13Th A New Beginning   \n",
       "15086  4.000000  1980                           When Time Ran Out   \n",
       "\n",
       "      close_match_type  \n",
       "45          wordsubset  \n",
       "52          wordsubset  \n",
       "61          wordsubset  \n",
       "67          wordsubset  \n",
       "71          wordsubset  \n",
       "81          wordsubset  \n",
       "99          wordsubset  \n",
       "104         wordsubset  \n",
       "114         wordsubset  \n",
       "118         wordsubset  \n",
       "133         wordsubset  \n",
       "166         wordsubset  \n",
       "173         wordsubset  \n",
       "187         wordsubset  \n",
       "227         wordsubset  \n",
       "239         wordsubset  \n",
       "240         wordsubset  \n",
       "259         wordsubset  \n",
       "262         wordsubset  \n",
       "265         wordsubset  \n",
       "268         wordsubset  \n",
       "303         wordsubset  \n",
       "313         wordsubset  \n",
       "317         wordsubset  \n",
       "330         wordsubset  \n",
       "336         wordsubset  \n",
       "363         wordsubset  \n",
       "392         wordsubset  \n",
       "411         wordsubset  \n",
       "441         wordsubset  \n",
       "...                ...  \n",
       "14286       wordsubset  \n",
       "14387       wordsubset  \n",
       "14421       wordsubset  \n",
       "14471       wordsubset  \n",
       "14475       wordsubset  \n",
       "14505       wordsubset  \n",
       "14521       wordsubset  \n",
       "14572       wordsubset  \n",
       "14612       wordsubset  \n",
       "14693       wordsubset  \n",
       "14732       wordsubset  \n",
       "14733       wordsubset  \n",
       "14758       wordsubset  \n",
       "14782       wordsubset  \n",
       "14799       wordsubset  \n",
       "14802       wordsubset  \n",
       "14831       wordsubset  \n",
       "14887       wordsubset  \n",
       "14896       wordsubset  \n",
       "14913       wordsubset  \n",
       "14962       wordsubset  \n",
       "14973       wordsubset  \n",
       "15001       wordsubset  \n",
       "15014       wordsubset  \n",
       "15027       wordsubset  \n",
       "15037       wordsubset  \n",
       "15045       wordsubset  \n",
       "15067       wordsubset  \n",
       "15075       wordsubset  \n",
       "15086       wordsubset  \n",
       "\n",
       "[750 rows x 8 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = films_all_w_cmtitles\n",
    "df = df[['genres', 'movieId', 'index', 'num_ratings', 'rating', 'year', 'title', 'close_match_type']][df['close_match_type'] == 'wordsubset']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[(df['title_match_type'] == 'close') & (df['year_match_on'] == 'next_year')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show films still not matched by movielens to IMDB\n",
    "df = films_all_w_cmtitles\n",
    "df = df[df['title'].isnull()]\n",
    "\n",
    "df_mm = df#[~df['genres'].str.contains('Documentary')&~df['genres'].str.contains('no genres listed')]\n",
    "\n",
    "df = films_all_w_cmtitles\n",
    "print('%s matches of movielens titles with imdb, from a total of %s movielens films.'\n",
    "      %(len(df[df['title'].notnull()]),len(df)))\n",
    "print('There are %s ''film'' films from movielens, still not matched from IMDb'%len(df_mm))\n",
    "df_mm.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quick IMDB title searcher\n",
    "def imdb(title):\n",
    "    return im[im['title'].str.contains(title)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imdb('Star Wars') # IMDB 'Star Wars' 1977, MovieLens 'Star Wars Episode Iv A New Hope' 1977 - FIXABLE (Year diff)\n",
    "#imdb('Cinema Paradiso') # Nuovo Cinema Paradiso in IMDB but 1988, instead of 1989 - FIXABLE (enclosed title)\n",
    "#imdb('Sherlock') #'Sherlock Holmes And Dr Watson Acquaintance' only in imdb online\n",
    "#imdb('The Blue Planet') #'The Blue Planet' only in imdb online (mini-series)\n",
    "#imdb('Gonna be great') #Everythin's Gonna Be Great only in imdb online\n",
    "#imdb('Lost Room') #The Lost Room online in imdb online (mini-series)\n",
    "#imdb('Once Brothers') # Not even on imdb online (Documentary)\n",
    "#imdb('Black Mirror') # Black Mirror 2011, only in imdb online (short)\n",
    "#imdb('Sherlock') #The Adventures Of Sherlock Holmes And Dr Watson The Hound Of The Baskervilles not even on imdb online\n",
    "#imdb('The Chaos Class') #The Dunce Class On Vacation only in imdb online\n",
    "#imdb('Band Of Brothers') #Band Of Brothers, only in imdb online (mini-series)\n",
    "#imdb('Life Is Beautiful') #Life is Beautiful 1997 only in imdb online - International -  NEED TO FIGURE OUt WHY\n",
    "#imdb('Le fabuleux') #Amelie 2001 only in imdb online - International - NEED TO FIGURE OUT WHY\n",
    "#imdb('Wallace And Gromit The Wrong Trousers') #Wallace And Gromit The Wrong Trousers not even in imdb\n",
    "#imdb('Heart Of A Dog') #Heart Of A Dog only in imdb (TV movie)\n",
    "#imdb('Kavkazskaya Plennitsa Ili Novye Priklyucheniya Shurika') - Title2 is Kavkazskaya Plennitsa - FIXABLE (enclosed title)\n",
    "#imdb('Decalogue') #The Decalogue - only in imdb online (tv miniseries)\n",
    "#imdb('World of tomorrow') #World of Tomorrow - only in imdb online (short)\n",
    "#imdb('Il Buono Il Brutto Il Cattivo') Title2 Buono Il Brutto Il Cattivo Il - FIXABLE (use algorithm for same words)\n",
    "#imdb('Wild Tales') # Only in imdb oneline - International - NEED TO FIGURE OUT WHY\n",
    "#imdb('Das Boot') # The Boot Das - FIXABLE (use algorithm for same words)\n",
    "#imdb('Creature Comforts') # Creature Comforts only in imdb online (short)\n",
    "#imdb('Brainstorm') #Brainstorm, not even in imdb online\n",
    "#imdb('Love And Honor') # Lovand And Honour 2007 in imdb, 2006 in movielens - FIXABLE (Year diff)\n",
    "#imdb('Cowboy Bebop') # Only in imdb online (tv series)\n",
    "#imdb('Formula of love') # Formula of love Only in imdb online (tv movie)\n",
    "#imdb('To Live') # Only in imdb oneline - International - NEED TO FIGURE OUT WHY\n",
    "#imdb('Some Folks Call It A Sling Blade') # only in imdb online (short)\n",
    "#imdb('Oldboy') #Old Boy 2003 FIXABLE (need word joiner search algorithm - could apply to all)\n",
    "#imdb('Que Horas') # The Second Mother - ALTERNATIVE IMDB TITLE WILL NEED MANUAL MAPPING\n",
    "#imdb('Léon')  # Only in imdb oneline - International - NEED TO FIGURE OUT WHY (There's another AKA too!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Experiments for FIXABLE (use algorithm for same words)\n",
    "#difflib.get_close_matches('Il Buono Il Brutto Il Cattivo', 'Buono Il Brutto Il Cattivo Il', cutoff = 0.1)\n",
    "x = 'Il Buono Il Brutto Il Cattivo'.split(' ')\n",
    "y = 'Buono Il Brutto Il Cattivo Il'.split(' ')\n",
    "set(x) == set(y)\n",
    "set(x) <= set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Experiments for FIXABLE (Year diff)\n",
    "df = df_mm.merge(im, left_on = 'title1', right_on = 'title')\n",
    "df[abs(df.year_x - df.year_y) <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Experimentation with my fav films spreadsheet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find out which of my top films are not matched in movielens or imdb\n",
    "# To be uses as a basis to fine-tune matching algorithm\n",
    "# (Need to make sure spreadhseet is not saved with - or ' autocorrect changes)\n",
    "df = pd.read_excel(data_dir + '/Me/top_films.xls', encoding = 'utf-8')\n",
    "my_films = df.merge(films_all, left_on = ['title'], right_on = ['title'], how = 'left')[['title', 'year', 'ml', 'im']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Break up my top films into various splices\n",
    "df = my_films\n",
    "my_films_no_ml = df[df['ml'].isnull() & df['im'].notnull()] # my top films that are NOT in movielens on title match alone\n",
    "my_films_no_im = df[df['im'].isnull() & df['ml'].notnull()] # my top films that are NOT in imdb on title match alone\n",
    "my_films_no_ml_im = df[df['ml'].isnull() & df['im'].isnull()] # my top films that are NOT in both of: movielens AND imdb on title match alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For my top films that mismatch between movielens and imdb, find closes matches to each set\n",
    "import difflib\n",
    "df = films_all\n",
    "df1_mm = df[df['im'].isnull()] # mis-matches - movielens films that don't have an imdb record\n",
    "df2_mm = df[df['ml'].isnull()] # mis-matches - imdb films that don't have a movielens record\n",
    "\n",
    "cut_off = 0.4\n",
    "my_films['ml_close_matches'] = my_films['title'].map(lambda x: difflib.get_close_matches(x, df1_mm['title'], cutoff = 0.2))\n",
    "my_films['im_close_matches'] = my_films['title'].map(lambda x: difflib.get_close_matches(x, df2_mm['title'], cutoff = 0.2))\n",
    "my_films#[my_films['ml'].isnull()|my_films['im'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1[df1['title'].str.contains(\"Up in the Air\")]['title'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2[df2['title'].str.contains(\"Love\")&df2['title'].str.contains(\"Drugs\")]['title']#.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2_mm[df2_mm['title'].str.contains(\"Love\")&df2_mm['title'].str.contains(\"Drugs\")]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difflib.get_close_matches('Love and Other Drugs', df2_mm['title'], cutoff = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2_mm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_films[my_films['title'].str.contains(\"When Harry\")]['title'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difflib.get_close_matches('Love and Other Drugs', ['Love & Other Drugs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating surveys for new users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create dataframe of films that users can review...\n",
    "\n",
    "# Remove films without an english language\n",
    "df = films_all\n",
    "df = df.merge(lan_om, left_on='id', right_on='movie_id')\n",
    "df = df[df.language_iso_639_1 == 'en']\n",
    "\n",
    "# Remove films made before 1965\n",
    "df = df[df.year >= 1965]\n",
    "\n",
    "# Remove films with < 10 number of ratings\n",
    "df = df[df.num_ratings >= 10]\n",
    "\n",
    "# Get rid of duplicates (since some films have mulitple lead-actor (n=1) and/or genre)\n",
    "df = df.drop_duplicates(subset=['index'])\n",
    "\n",
    "# Sort by best films at the start\n",
    "df = df.sort_values(by=['rating', 'num_ratings'], ascending=[False, False])\n",
    "\n",
    "films_reviewable = df\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomise DataFrame, by placing the top 500 films in random order, then the remaining films in random order\n",
    "# This is in an attempt to reduce a bias, that people will typically rate more prestigious films higher \n",
    "# as they would appear that way in the list otherwise. For example Schindler's List, The Godfather etc are well known to rate highly\n",
    "# Print out 30 random copies of this to be imported into google sheets\n",
    "df = films_reviewable.head(1000).copy()\n",
    "num_surveys = 30\n",
    "for i in range(num_surveys):\n",
    "    top500 = df.head(500)\n",
    "    top500 = top500.reindex(pd.np.random.permutation(top500.index))\n",
    "    remainder = df.tail(500)\n",
    "    remainder = remainder.reindex(pd.np.random.permutation(remainder.index))\n",
    "    films_reviewable_randomised = top500.append(remainder)\n",
    "    films_reviewable_randomised.head()\n",
    "\n",
    "    # Output to Excel to then be imported manually into Google Sheets for new user to review\n",
    "    #(is quicker than writing directly to google sheets from pandas)\n",
    "    films_reviewable_randomised[['title','year','lead actor','genres','index']].to_excel('output%d.xlsx' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output the remaining fims to review into excel (not including top 1000)\n",
    "# (Only for power users)\n",
    "df = films_reviewable.tail(len(films_reviewable)-1000).copy()\n",
    "df = df.reindex(pd.np.random.permutation(df.index))\n",
    "\n",
    "# Output to Excel to then be imported manually into Google Sheets for new user to review\n",
    "#(is quicker than writing directly to google sheets from pandas)\n",
    "df[['title','year','lead actor','genres','index']].to_excel('after_top_1000.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating profiles for new users (see also below)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to read in and clean-up new user ratings data from Google Sheets\n",
    "def read_new_user_ratings(workbook_name, sheet_name):\n",
    "    # Read in data\n",
    "    workbook = gc.open(workbook_name)\n",
    "    df = pd.DataFrame(workbook.worksheet(sheet_name).get_all_records())\n",
    "    \n",
    "    # Convert 'out of 10' column to correct data\n",
    "    df.loc[(df['out of 10']=='')|(df['out of 10']=='-'),'out of 10'] = -1\n",
    "    df['out of 10'] = df['out of 10'].astype(int)\n",
    "    \n",
    "    # (For the time being) remove all films new user has not reviewed (ie they haven't yet seen)\n",
    "    df = df[df['out of 10'] >= 0]\n",
    "    \n",
    "    # Add to dictionary\n",
    "    users[workbook_name][sheet_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Dynamically read new user ratings from various google sheets\n",
    "\n",
    "# Adapted from merging code between: \n",
    "# http://gspread.readthedocs.io/en/latest/oauth2.html - Setting up the authentication\n",
    "# http://pbpython.com/pandas-google-forms-part1.html - Structure of code (with different 'credentials' var to above)\n",
    "# https://github.com/burnash/gspread - Reading and manipulating the google sheet\n",
    "\n",
    "from __future__ import print_function\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Authenication and Google Sheet Parameters & Variables\n",
    "SCOPE = [\"https://spreadsheets.google.com/feeds\"]\n",
    "SECRETS_FILE = \"/Users/justinbarton/Documents/DevSetup/Justin-ee2a176f3e01.json\"\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(SECRETS_FILE, SCOPE)\n",
    "\n",
    "# Authorise the Google Sheet to open it.\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "# Define variables to open spreadsheets and hold new user ratings\n",
    "users = {}\n",
    "\n",
    "# Read my own user ratings\n",
    "users['Films_Justin'] = {}\n",
    "read_new_user_ratings('Films_Justin', 'Reviewed')\n",
    "\n",
    "# Read new user ratings\n",
    "users['Films_Barton'] = {}\n",
    "read_new_user_ratings('Films_Barton', 'Damian')\n",
    "read_new_user_ratings('Films_Barton', 'Jess')\n",
    "\n",
    "users['Films_Barker'] = {}\n",
    "read_new_user_ratings('Films_Barker', 'Dave')\n",
    "read_new_user_ratings('Films_Barker', 'Andreas')\n",
    "read_new_user_ratings('Films_Barker', 'Below')\n",
    "read_new_user_ratings('Films_Barker', 'LindaBelow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating feature tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data: MovieLens\n",
    "# Create dataframe 'films_all_jobs' containing: all movies: 'movie_id' (OMDB) 'index' (IMDB), jobs 'job_name' and people 'person'\n",
    "# (and various other info associated with those people and roles.)\n",
    "job_full_om = job_om.merge(cst_om, left_on='job_id', right_on='job_id')\n",
    "mov_jobs_om = job_full_om.merge(ppl_om, left_on='person_id', right_on='id')\n",
    "mov_jobs_om.rename(columns={'name_x':'job_name', 'name_y':'person', 'id':'person_id'}, inplace=True) # Rename fields, to avoid future confusion upon merging\n",
    "films_all_jobs = mov_jobs_om.merge(films_all[['index', 'id']], left_on = 'movie_id', right_on = 'id')\n",
    "films_all_jobs.drop(['id'], axis=1, inplace = True)\n",
    "films_all_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data: MovieLens & IMDB & OMDB\n",
    "# Create dataframe 'films_all_actors' containing: all movies 'movie_id' (MovieLens) or 'index' (IMDB), actors 'actor', \n",
    "# 'actor_rank_for_movie' (the smaller the number the higher ranked in that film)\n",
    "\n",
    "# Set parameter for the maximum number of actors to have for each film, retaining only the highest ranked.\n",
    "max_actors = 10\n",
    "\n",
    "# Get actor and rank info from imdb\n",
    "df2 = mov_cst_im[['index','name','type','n']]\n",
    "df2 = df2[df2.n.notnull()]\n",
    "df2 = df2[df2.n <= max_actors]\n",
    "\n",
    "# Add actor and rank info\n",
    "df = films_all\n",
    "df = df.merge(df2, left_on='index', right_on='index')\n",
    "df.rename(columns={'name':'Actor', 'type':'is_male_actor', 'n':'actor_rank_for_movie'}, inplace=True)\n",
    "df['is_male_actor'] = df['is_male_actor'] == 'actor'\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "films_all_actors = df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data: MovieLens & IMDB & OMDB\n",
    "# Create dataframe 'films_all_det' containing all movies 'id' (OMDB) or 'index' (IMDB), 'revenue', 'budget', 'runtime'\n",
    "df = det_om[['movie_id', 'runtime', 'budget', 'revenue']]\n",
    "df = df[(df.runtime != 0)|(df.budget != 0)|df.revenue != 0] # Make sure at least one of 'runtime', 'budget' and 'revenue' is non-zero\n",
    "\n",
    "df = df.merge(films_all, left_on = 'movie_id', right_on = 'id')\n",
    "films_all_det = df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define features, using feature_name as their key. And provide their:\n",
    "# 1) df = DataFrame (must have films indexed with column name 'index')\n",
    "# 2) (column_name_containing_feature, column_name_feature_data)  (use False if the feature_name (the key) is the column_name)\n",
    "# 3) has_zero_records - is True if this feature has some records that are indicated by 0\n",
    "#   Otherwise the value to indicate null record will be given (e.g. False, 0, NaN etc..)\n",
    "#    (this only applies to those whose column_name = feature_name)\n",
    "features = {}\n",
    "\n",
    "feats = ['num_ratings', 'rating', 'year']\n",
    "for f in feats:\n",
    "    features[f] = (films_all, False, False)\n",
    "\n",
    "features['Actor'] = (films_all_actors, False, False)\n",
    "\n",
    "feats = ['Director', 'Screenplay', 'Producer', 'Director of Photography', \n",
    "         'Editor', 'Original Music Composer', 'Music', 'Executive Producer']\n",
    "for f in feats:\n",
    "    features[f] = (films_all_jobs, ('job_name', 'person'), False)\n",
    "\n",
    "feats = ['runtime', 'budget', 'revenue']\n",
    "for f in feats:\n",
    "    features[f] = (films_all_det, False, True)\n",
    "    \n",
    "    \n",
    "# Define feature selection tuning parameters\n",
    "good_films_threshold = 7 # Films equal to or greater than this will be labelled 'GOOD'\n",
    "bad_films_threshold = 5 # Films equal to or less than this will be labelled 'BAD'\n",
    "min_feature_count_threshold = 1 # Need to have at least this many 'good' films of discrete features, for feature to be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to add features to a dataframe df (has to have imdb linker 'index')\n",
    "# Features are:\n",
    "# --BASIC INFO--\n",
    "# 'num_ratings', 'ratings', 'year'\n",
    "# --JOB TITLES--\n",
    "# 'Actor', 'Director', 'Screenplay', 'Producer', 'Director of Photography', 'Editor', 'Original Music Composer'\n",
    "# 'Editor','Executive Producer', 'Music'\n",
    "# --MOVIE DETAILS--\n",
    "# runtime (mins), budget, revenue\n",
    "\n",
    "def add_features(df, feature_names):\n",
    "\n",
    "    # Go through and add all features to df\n",
    "    for feature_name in feature_names:\n",
    "        \n",
    "        # Gather important variables for this feature\n",
    "        feature = features[feature_name]\n",
    "        feat_df = feature[0]\n",
    "        column_name_is_feature_name = feature[1] == False\n",
    "        if column_name_is_feature_name == False:\n",
    "            column_name_containing_feature = feature[1][0]\n",
    "            column_name_feature_data = feature[1][1]\n",
    "        has_zero_records = feature[2]\n",
    "\n",
    "        # Add features, when feature_name is column_name\n",
    "        if column_name_is_feature_name:\n",
    "            # Remove null records of feature (if applicable)\n",
    "            df2 = feat_df[['index', feature_name]]\n",
    "            if has_zero_records:\n",
    "                df2 = df2[df2[feature_name] > 0]\n",
    "            \n",
    "            # Add feature\n",
    "            df = df.merge(df2, how = 'left')\n",
    "\n",
    "        # Add features, when needing to use 2 columns to get feature\n",
    "        else:\n",
    "            df2 = feat_df[feat_df[column_name_containing_feature] == feature_name][['index', column_name_feature_data]]\n",
    "            df = df.merge(df2, how = 'left')\n",
    "            df.rename(columns = {column_name_feature_data:feature_name}, inplace = True)\n",
    "\n",
    "        # Delete duplicates that have crept in\n",
    "        df.drop_duplicates(inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a column to show the values counts of a feature (per film in df)\n",
    "# Then sort by that column count, and return dataframe\n",
    "# df = dataframe to modify and output (must have imdb movie indentifer 'index')\n",
    "# feature = the name of said feature\n",
    "def sort_by_feature_count(df, feature):\n",
    "    df2 = pd.DataFrame(df[['index', feature]].drop_duplicates()[feature].value_counts())\n",
    "    df2 = df2.rename(columns = {feature : '%s_count' % feature})\n",
    "    df = df.merge(df2, left_on = feature, right_index = True)\n",
    "    df.sort_values('%s_count' % feature, ascending = False, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Output a dataframe for this user, showing the maximum number of occurances within this feature\n",
    "# This only works for discrete features, (NOT continuous features like revenue, budget and runtime etc)\n",
    "# If bad_films is True, will show the results for users bad films, instead of the default, good films\n",
    "def top_discrete_features(sheet_name, user_name, feature, bad_films = False):\n",
    "    df = users[sheet_name][user_name]\n",
    "    if bad_films:\n",
    "        df = add_features(df[df['out of 10'] <= bad_films_threshold], [feature])\n",
    "    else:\n",
    "        df = add_features(df[df['out of 10'] >= good_films_threshold], [feature])\n",
    "    df = sort_by_feature_count(df, feature)\n",
    "    df[df['%s_count' % feature] >= min_feature_count_threshold]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating profiles for new users (continued)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Graphing capability for function: top_discrete_features\n",
    "# max_disp_results = maximum number of values to display on the graph \n",
    "# (e.g. if feature_name = 'Director' and max_disp_results = 5, it would display 5 top actors)\n",
    "def graph_top_discrete_features(sheet_name, user_name, feature, max_disp_results, bad_films = False):\n",
    "    df = top_discrete_features(sheet_name, user_name, feature, bad_films)\n",
    "    df = df[[feature, '%s_count' % feature]].drop_duplicates()\n",
    "    df = df.head(max_disp_results)\n",
    "    if len(df != 0):\n",
    "        df.plot(x = feature, y = '%s_count' % feature, kind = 'barh', \n",
    "                title = \"%s's %spreferred %ss\" % (user_name, ('','non-')[bad_films] ,feature), \n",
    "                legend = False)\n",
    "    else:\n",
    "        print('%s has no %spreferred %ss' % (user_name, ('','non-')[bad_films] ,feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display Top Preferred and Non-Preferred features for new users\n",
    "test_features = ['Actor','Director', 'Producer', 'Director of Photography', 'Screenplay', 'Original Music Composer']\n",
    "\n",
    "for sheet, usrs in users.iteritems():\n",
    "    for usr in usrs:\n",
    "        for feature in test_features:\n",
    "            graph_top_discrete_features(sheet, usr, feature, 10, bad_films = False)\n",
    "            graph_top_discrete_features(sheet, usr, feature, 10, bad_films = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression on film attributes - per new user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Linear Regression Models for each user, using only continuous variables\n",
    "# that are film attributes\n",
    "# For each user:\n",
    "# Try a model with all feaures, and a model with each feature individually\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "test_features = ['year','num_ratings','rating','runtime', 'budget', 'revenue']\n",
    "results = {}\n",
    "for sheet, usrs in users.iteritems():\n",
    "    for usr in usrs:\n",
    "        \n",
    "        # Results table\n",
    "        sheet_user = '%s %s' % (sheet, usr)\n",
    "        results[sheet_user] = {}\n",
    "        \n",
    "        # Create dataframe, and show number of films rated\n",
    "        df = users[sheet][usr]\n",
    "        results[sheet_user]['Films_rated'] = len(df)\n",
    "\n",
    "        df = add_features(df, test_features)\n",
    "        # Make sure each feature has a value in every row\n",
    "        for feat in test_features:\n",
    "            df = df[df[feat].notnull()]\n",
    "            \n",
    "        # Linear regression on all features\n",
    "        X_train, X_test, Y_train, Y_test = sklearn.cross_validation.train_test_split(\n",
    "            df[test_features], df['out of 10'])\n",
    "        lm = LinearRegression()\n",
    "        lm.fit(X_train, Y_train)\n",
    "\n",
    "        results[sheet_user]['All_feats_R^2_Train'] = lm.score(X_train, Y_train)\n",
    "        results[sheet_user]['All_feats_R^2_Test'] = lm.score(X_test, Y_test)\n",
    "            \n",
    "        # Linear regression on features individually\n",
    "        for feature in test_features:\n",
    "            X_train, X_test, Y_train, Y_test = sklearn.cross_validation.train_test_split(\n",
    "            df[[feature]], df['out of 10'])\n",
    "            lm = LinearRegression()\n",
    "            lm.fit(X_train, Y_train)\n",
    "            \n",
    "            results[sheet_user]['%s_R^2_Train' % feature] = lm.score(X_train, Y_train)\n",
    "            results[sheet_user]['%s_R^2_Test' % feature] = lm.score(X_test, Y_test)\n",
    "            \n",
    "df = pd.DataFrame(results).transpose().drop(['Films_rated'], axis = 1).plot(kind='bar', legend = False)\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression on old user ratings - per new user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For new user defined by [sheet_name][user_name], find all historial users, who have rated the same films\n",
    "# Add these users and their ratings as new columns to Dataframe df returned (indentified as UserId)  \n",
    "# Count the number of films, historical users and new user have both rated.\n",
    "# Optional parameters:\n",
    "# only_match_good: only find historial users that match on good films\n",
    "# max_num_users: the maximum number of users to return\n",
    "# min_common_films: the minimum number of shared rated films, \n",
    "#    from new user to old user to include in df\n",
    "def find_hist_users(sheet_name, user_name, only_match_good = False, max_num_users = pd.np.Inf, min_common_films = -pd.np.Inf):\n",
    "    global old_rats\n",
    "    usr = users[sheet_name][user_name] # new user ratings\n",
    "    \n",
    "    # Retain only good films from new and old users (if applicable)\n",
    "    if only_match_good:\n",
    "        usr = usr[ usr['out of 10'] >= good_films_threshold ]\n",
    "        old_rats = old_rats[old_rats['user_rating'] >= good_films_threshold]\n",
    "    \n",
    "    # Merge new user ratings, with old\n",
    "    df = old_rats.merge(usr, left_on = 'index', right_on = 'index')\n",
    "    df.drop_duplicates(inplace = True)\n",
    "    \n",
    "    # Count the number common films reviwed between new user, and old users\n",
    "    gb = df[['userId', 'index']].groupby('userId').count()\n",
    "    gb.rename(columns={'index':'common_films_count'}, inplace = True)\n",
    "    \n",
    "    # Remove old users that did not hit the min_common_films threshold\n",
    "    gb = gb[gb['common_films_count'] >= min_common_films]\n",
    "    gb.reset_index(inplace = True)\n",
    "    gb.sort_values(by = 'common_films_count', ascending = False, inplace = True)\n",
    "    \n",
    "    # Create final dataframe, and cut off at the maximum number of users to find\n",
    "    gb = gb.head(min(len(gb), max_num_users))\n",
    "    df = gb.merge(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert hist_users_with_new into a user features dataframe. (used after find_hist_users)\n",
    "# hist_users_with_new must have columns:\n",
    "# 'index' - film indentifer\n",
    "# 'userId' - historial user indentifier\n",
    "# 'user_rating' - historal user_rating\n",
    "# 'out of 10' - new user rating\n",
    "# 'common_films_count' - the  number of shared rated films, from new user to old user\n",
    "# New columns names added will be 'userId', for all userIds\n",
    "# The number of new columns added will be capped by:\n",
    "# max_features - the maximum number of userId_d columns to add\n",
    "def create_hist_user_features(hist_users_with_new, max_features = pd.np.Inf):\n",
    "    df = hist_users_with_new\n",
    "    df = df[['userId', 'common_films_count']]\n",
    "    df.drop_duplicates(inplace = True)\n",
    "    df.sort_values(by = 'common_films_count', ascending = False, inplace = True)\n",
    "    feats = df.head(min(len(df),max_features))[['userId']]\n",
    "    \n",
    "    df = hist_users_with_new.merge(feats, left_on = 'userId', right_on = 'userId')\n",
    "    \n",
    "    df = df[['index', 'userId','user_rating','out of 10']]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform pivot table, with normal pandas fields: 'values', 'index', 'column'\n",
    "# Remove na values in pivot table, then..\n",
    "# Add columns 'keep_cols' in the final table, whose values correspond with 'index'\n",
    "#   Note: the 'keep_cols' are NOT pivoted, and can't be part of 'columns'\n",
    "# If dropna == True, will make sure all features have a value \n",
    "#   Note: to be used when running directly in a regression model\n",
    "def pivot_and_keep_cols(df, values, index, columns, keep_cols = [], dropna = True):\n",
    "    piv = df.pivot_table(values = 'user_rating', index = 'index', columns = 'userId')\n",
    "    if dropna:\n",
    "        piv.dropna(inplace = True)\n",
    "    df = piv.merge(df[keep_cols+[index]], left_index = True, right_on = index)\n",
    "    return df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run multiple linear regression models for each new user, on old users ratings as features\n",
    "# Same field descriptions as above, store results in 'results'\n",
    "def run_linreg_hist_users(sheet_name, user_name, max_num_users, only_match_good, results):\n",
    "    # Transform the data\n",
    "    df = find_hist_users(sheet_name = sheet_name, user_name = user_name, \n",
    "                         max_num_users = max_num_users, only_match_good = only_match_good)\n",
    "    df = create_hist_user_features(df)\n",
    "    df = pivot_and_keep_cols(df, values = 'user_rating', index = 'index', columns = 'userId', keep_cols = ['out of 10'])\n",
    "    \n",
    "    # Run the linear regression\n",
    "    feats = df.drop(['out of 10', 'index'], axis = 1)\n",
    "    test_score = pd.np.nan\n",
    "    train_score = pd.np.nan\n",
    "    if len(feats) >= 2: # Only run linear regression if there is enough data to do so\n",
    "        X_train, X_test, Y_train, Y_test = sklearn.cross_validation.train_test_split(\n",
    "                feats, df['out of 10'])\n",
    "        lm = LinearRegression()\n",
    "        lm.fit(X_train, Y_train)\n",
    "        test_score = lm.score(X_test, Y_test)\n",
    "        train_score = lm.score(X_train, Y_train)\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({'User':'%s %s'%(sheet_name, user_name), \n",
    "                   'Amount rated by user':len(users[sheet_name][user_name]),\n",
    "                   'Amount of old users':feats.shape[1],\n",
    "                   'Amount of films in common':feats.shape[0],\n",
    "                   'Good films only':only_match_good, \n",
    "                   'R^2_Train':train_score,\n",
    "                   'R^2_Test':test_score})\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run linear regression models for all users, against previous users, tweaking both:\n",
    "#   number of users to use as features (dimensions, d), \n",
    "#   and only finding users that match on good films or not\n",
    "%time\n",
    "results = []\n",
    "result_fields = ('User', 'Amount rated by user', 'Amount of old users', 'Amount of films in common',\n",
    "                 'Good films only', 'R^2_Train', 'R^2_Test')\n",
    "dimensions = [1, 2, 5, 10, 20, 50, 100, 200, 500]\n",
    "for sheet, usrs in users.iteritems():\n",
    "    for usr in usrs:\n",
    "        for d in dimensions:\n",
    "            run_linreg_hist_users(sheet, usr, max_num_users = d, only_match_good = True, results = results)\n",
    "            run_linreg_hist_users(sheet, usr, max_num_users = d, only_match_good = False, results = results)\n",
    "df = pd.DataFrame(results, columns = result_fields)\n",
    "mult_lin_reg_old_users = df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show the R^2 scores distribution for each users\n",
    "mult_lin_reg_old_users[['User', 'Amount rated by user', 'R^2_Train', 'R^2_Test']].groupby(['User', 'Amount rated by user']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the heaviest and the lightest film raters, to see how many old users have also rated these films\n",
    "heaviest = df[df['User'] == 'Films_Justin Reviewed']\n",
    "heaviest.plot(kind = 'scatter', x = 'Amount of old users', \n",
    "    y = 'Amount of films in common', title = 'Heaviest film rater: %s films' % len(users['Films_Justin']['Reviewed']),\n",
    "    xlim = (0,max(heaviest['Amount of old users'])), ylim = (0,max(heaviest['Amount of films in common'])))\n",
    "\n",
    "lightest = df[df['User'] == 'Films_Barker Andreas']\n",
    "lightest.plot(kind = 'scatter', x = 'Amount of old users', \n",
    "    y = 'Amount of films in common', title = 'Lighest film rater: %s films' % len(users['Films_Barker']['Andreas']),\n",
    "    xlim = (0,max(lightest['Amount of old users'])), ylim = (0,max(lightest['Amount of films in common'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the relationship between number of 'Amount of old users' vs 'Amount of films in common' across the board\n",
    "df.plot(kind = 'scatter', x = 'Amount of old users', \n",
    "    y = 'Amount of films in common', title = \"'Amount of old users' vs 'Amount of films in common'\",\n",
    "    xlim = (0,max(df['Amount of old users'])), ylim = (0,max(df['Amount of films in common'])))\n",
    "df.plot(kind = 'scatter', x = 'Amount of old users', \n",
    "    y = 'Amount of films in common', title = \"'Amount of old users' vs 'Amount of films in common' (zoomed in on corner)\",\n",
    "    xlim = (0,100), ylim = (0,250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Finding old users with similar ratings to new users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each new user, find similar users from on old users ratings\n",
    "# Same field descriptions as above\n",
    "# Tolerance - how close as ratio difference, must both the mean and std of new user ratings be to be included\n",
    "# results dictionary 'similiar_users' of dataframes indexed by 'sheet_name user_name'\n",
    "def find_similar_hist_users(sheet_name, user_name, max_num_users, only_match_good, tolerance, similiar_users):\n",
    "    \n",
    "    df = find_hist_users(sheet_name, user_name, max_num_users = max_num_users, only_match_good = only_match_good)\n",
    "    df = create_hist_user_features(df)\n",
    "    \n",
    "    df = pivot_and_keep_cols(df, values = 'user_rating', index = 'index', columns = 'userId', \n",
    "                          keep_cols = ['out of 10'], dropna = False)\n",
    "\n",
    "    # List to store the results\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    # Loop through all old users, and record how similar their scores are based on: mean, median, std etc\n",
    "    old_users = list(df.columns)[:-2]\n",
    "    for u in old_users:\n",
    "        df1 = df[df['out of 10'].notnull()&df[u].notnull()][['out of 10', u]].describe().transpose()\n",
    "        df1.rename(index = {u:'userId'}, inplace = True)\n",
    "        df1 = pd.DataFrame(df1.unstack()).transpose()\n",
    "        df1.rename(index = {0:u}, inplace = True)\n",
    "        results = results.append(df1)\n",
    "    \n",
    "    # Add 'diff' values to compare the results - (linking back to the tolerance above)\n",
    "    results['mean', 'diff'] = abs((results['mean', 'out of 10'] - results['mean', 'userId'])/results['mean', 'out of 10'])\n",
    "    results['std', 'diff'] = abs((results['std', 'out of 10'] - results['std', 'userId'])/results['std', 'out of 10'])\n",
    "    \n",
    "    # Remove those outside of the tolerance\n",
    "    results = results[ results['mean', 'diff'] <= tolerance ]\n",
    "    results = results[ results['std', 'diff'] <= tolerance ]\n",
    "    \n",
    "    # Sort results and save\n",
    "    results.sort_values(by = [('std', 'diff'), ('mean', 'diff')])\n",
    "    similiar_users['%s %s' % (sheet_name, user_name)] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the most similar raters for each user\n",
    "# This takes ages and/or locks up the computer, so it won't be run all the time.\n",
    "have_good_computer = False\n",
    "similiar_users = {}\n",
    "if have_good_computer:\n",
    "    for sheet, usrs in users.iteritems():\n",
    "        for usr in usrs:\n",
    "            find_similar_hist_users(sheet, usr, max_num_users = pd.np.Inf, only_match_good = True, \n",
    "                tolerance = 0.05, similiar_users = similiar_users)\n",
    "            \n",
    "# Instead do this for a single user:\n",
    "find_similar_hist_users('Films_Justin', 'Reviewed', max_num_users = 200, only_match_good = True, \n",
    "                tolerance = 0.10, similiar_users = similiar_users)\n",
    "similiar_users['Films_Justin Reviewed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From Justin's similar users above, find films these users have rating as good films\n",
    "# These will form the basis for the first recommendations\n",
    "\n",
    "LAF_threshold = 8 # Life altering film threshold (score out of 10)\n",
    "\n",
    "# Get just the 'userId's of all of the old users who are similar\n",
    "df = similiar_users['Films_Justin Reviewed']\n",
    "df.drop(list(df.columns), axis = 1, inplace = True)\n",
    "\n",
    "# Find LAFs from these similar users\n",
    "df = old_rats.merge(df, left_on = 'userId', right_index = True)\n",
    "df = df[df['user_rating'] >= LAF_threshold]\n",
    "df = df[['index']]\n",
    "df.drop_duplicates(inplace = True)\n",
    "df = films_all.merge(df, left_on = 'index', right_on = 'index')[['title', 'year', 'genres', 'lead actor','index']]\n",
    "\n",
    "# Remove films I've already seen, and display results\n",
    "tmp = df[['index']].merge(users['Films_Justin']['Reviewed'][['title','index']], left_on = 'index', right_on = 'index', how='left')\n",
    "unwatched_films = tmp[tmp['title'].isnull()][['index']]\n",
    "recommendations = unwatched_films.merge(df, left_on = 'index', right_on = 'index')\n",
    "recommendations.drop_duplicates(subset = ['title', 'year'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
